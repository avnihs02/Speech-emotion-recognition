{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################ IMPORTING THE REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout,Flatten,BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############## EMOTIONS INCLUDED IN THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############## EXTRACTING FEATURES FROM THE AUDIO SIGNAL USING LIBROSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_feature(file_name, mfcc, chroma,spectral_centroid,spectral_bandwidth,\n",
    "                    spectral_rolloff,spectral_contrast,rms,spectral_flatness):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "            \n",
    "            \n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))             \n",
    "           \n",
    "            \n",
    "        if spectral_centroid:\n",
    "            spectral_centroid=np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate))\n",
    "            result=np.hstack((result, spectral_centroid)) \n",
    "        \n",
    "        if spectral_bandwidth:\n",
    "           spectral_bandwidth=np.mean(librosa.feature.spectral_bandwidth(y=X, sr=sample_rate).T)\n",
    "#           print(spectral_bandwidth)\n",
    "           result=np.hstack((result, spectral_bandwidth)) \n",
    "           \n",
    "        if spectral_rolloff:\n",
    "           spectral_rolloff=np.mean(librosa.feature.spectral_rolloff(y=X, sr=sample_rate).T)\n",
    "#           print(spectral_rolloff)\n",
    "           result=np.hstack((result, spectral_rolloff))\n",
    "        \n",
    "        if spectral_contrast:\n",
    "           spectral_contrast=np.mean(librosa.feature.spectral_contrast(y=X, sr=sample_rate))\n",
    "           result=np.hstack((result, spectral_contrast))\n",
    "           \n",
    "        if rms:\n",
    "           rms=np.mean(librosa.feature.rms(y=X).T,axis=0)\n",
    "           result=np.hstack((result, rms))\n",
    "           \n",
    "        if spectral_flatness:\n",
    "           spectral_flatness=np.mean(librosa.feature.spectral_flatness(y=X))\n",
    "           result=np.hstack((result, spectral_flatness))\n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############## LOADING THE DATASET AND EXTRACTING ALL THE FEATURES FROM IT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"F:\\\\speech_project\\\\Actor_*\\\\*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True,spectral_centroid=True,spectral_bandwidth=True,\n",
    "                                spectral_rolloff=True,spectral_contrast=True,rms=True,spectral_flatness=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    # Create scaler: scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X=scaler.fit_transform(x)\n",
    "    X=pd.DataFrame(X)\n",
    "    ############ \n",
    "    tsne = TSNE(learning_rate=200,random_state=2019)\n",
    "    # Apply fit_transform to samples: tsne_features\n",
    "    tsne_features = tsne.fit_transform(X)\n",
    "    return tsne_features,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############## SHUFFLING OF OBS AND RESETTING THE OBS INDEXES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=load_data()\n",
    "X=pd.DataFrame(X)\n",
    "y=pd.DataFrame(y)\n",
    "data=pd.concat([X,y],axis=\"columns\")\n",
    "data=data.sample(frac=1).reset_index(drop=True)\n",
    "X=data.iloc[:,0:58]\n",
    "y=data.iloc[:,58]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############## LABEL ENCODING THE RESPONSE VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############## SPLITTING THE DATA INTO TRAIN(95%) AND TEST(5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "print((x_train.shape[0], x_test.shape[0]))\n",
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############## RESHAPING PREDICTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(x_train, axis=2)\n",
    "x_testcnn = np.expand_dims(x_test, axis=2)\n",
    "print(x_traincnn.shape)\n",
    "print(x_testcnn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############## LABEL ENCODING THE RESPONSE VARIABLES AND CREATING DUMMIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 2\n",
      "(1311, 8)\n",
      "(69, 8)\n"
     ]
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############ 1D CNN #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(332, 7, padding='same',input_shape=(x_traincnn.shape[1],1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(280, 7, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=(2),strides=2))\n",
    "model.add(Conv1D(305, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(325, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(1),strides=1))\n",
    "model.add(Conv1D(201, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(300, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "#opt =SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################### TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 1311 samples, validate on 69 samples\n",
      "Epoch 1/150\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dbda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      " - 4s - loss: 1.9937 - acc: 0.2006 - val_loss: 2.0693 - val_acc: 0.1594\n",
      "Epoch 2/150\n",
      " - 3s - loss: 1.9468 - acc: 0.2159 - val_loss: 2.0081 - val_acc: 0.1449\n",
      "Epoch 3/150\n",
      " - 3s - loss: 1.9207 - acc: 0.2182 - val_loss: 2.1065 - val_acc: 0.1304\n",
      "Epoch 4/150\n",
      " - 3s - loss: 1.9125 - acc: 0.2365 - val_loss: 2.1528 - val_acc: 0.1739\n",
      "Epoch 5/150\n",
      " - 3s - loss: 1.8863 - acc: 0.2517 - val_loss: 2.0415 - val_acc: 0.2029\n",
      "Epoch 6/150\n",
      " - 3s - loss: 1.8756 - acc: 0.2639 - val_loss: 2.0559 - val_acc: 0.1594\n",
      "Epoch 7/150\n",
      " - 3s - loss: 1.8713 - acc: 0.2685 - val_loss: 1.9770 - val_acc: 0.1304\n",
      "Epoch 8/150\n",
      " - 3s - loss: 1.8711 - acc: 0.2693 - val_loss: 2.0194 - val_acc: 0.1739\n",
      "Epoch 9/150\n",
      " - 3s - loss: 1.8368 - acc: 0.2784 - val_loss: 2.0733 - val_acc: 0.1739\n",
      "Epoch 10/150\n",
      " - 3s - loss: 1.8212 - acc: 0.2838 - val_loss: 2.1466 - val_acc: 0.1594\n",
      "Epoch 11/150\n",
      " - 3s - loss: 1.8401 - acc: 0.3028 - val_loss: 2.0886 - val_acc: 0.1739\n",
      "Epoch 12/150\n",
      " - 3s - loss: 1.8120 - acc: 0.2891 - val_loss: 1.9865 - val_acc: 0.1884\n",
      "Epoch 13/150\n",
      " - 3s - loss: 1.7984 - acc: 0.2921 - val_loss: 2.0916 - val_acc: 0.1884\n",
      "Epoch 14/150\n",
      " - 3s - loss: 1.7985 - acc: 0.3013 - val_loss: 1.9760 - val_acc: 0.1594\n",
      "Epoch 15/150\n",
      " - 3s - loss: 1.7947 - acc: 0.2975 - val_loss: 2.0013 - val_acc: 0.1884\n",
      "Epoch 16/150\n",
      " - 3s - loss: 1.7648 - acc: 0.3066 - val_loss: 2.0389 - val_acc: 0.2319\n",
      "Epoch 17/150\n",
      " - 3s - loss: 1.7717 - acc: 0.3013 - val_loss: 2.1897 - val_acc: 0.1304\n",
      "Epoch 18/150\n",
      " - 4s - loss: 1.7752 - acc: 0.3188 - val_loss: 2.0439 - val_acc: 0.1739\n",
      "Epoch 19/150\n",
      " - 3s - loss: 1.7549 - acc: 0.3234 - val_loss: 2.0483 - val_acc: 0.1739\n",
      "Epoch 20/150\n",
      " - 5s - loss: 1.7389 - acc: 0.3318 - val_loss: 1.9674 - val_acc: 0.2464\n",
      "Epoch 21/150\n",
      " - 3s - loss: 1.7368 - acc: 0.3272 - val_loss: 2.0508 - val_acc: 0.1884\n",
      "Epoch 22/150\n",
      " - 3s - loss: 1.7043 - acc: 0.3341 - val_loss: 2.1661 - val_acc: 0.2174\n",
      "Epoch 23/150\n",
      " - 3s - loss: 1.6823 - acc: 0.3600 - val_loss: 1.9756 - val_acc: 0.2464\n",
      "Epoch 24/150\n",
      " - 3s - loss: 1.6921 - acc: 0.3295 - val_loss: 2.0217 - val_acc: 0.2029\n",
      "Epoch 25/150\n",
      " - 3s - loss: 1.6741 - acc: 0.3532 - val_loss: 2.0140 - val_acc: 0.2464\n",
      "Epoch 26/150\n",
      " - 4s - loss: 1.6716 - acc: 0.3539 - val_loss: 1.9482 - val_acc: 0.2174\n",
      "Epoch 27/150\n",
      " - 3s - loss: 1.6713 - acc: 0.3501 - val_loss: 2.0024 - val_acc: 0.2464\n",
      "Epoch 28/150\n",
      " - 3s - loss: 1.6903 - acc: 0.3524 - val_loss: 1.9478 - val_acc: 0.2319\n",
      "Epoch 29/150\n",
      " - 3s - loss: 1.6517 - acc: 0.3524 - val_loss: 2.0966 - val_acc: 0.1884\n",
      "Epoch 30/150\n",
      " - 3s - loss: 1.6821 - acc: 0.3371 - val_loss: 1.9884 - val_acc: 0.3043\n",
      "Epoch 31/150\n",
      " - 3s - loss: 1.6116 - acc: 0.3692 - val_loss: 2.0499 - val_acc: 0.2464\n",
      "Epoch 32/150\n",
      " - 3s - loss: 1.5977 - acc: 0.3791 - val_loss: 2.0166 - val_acc: 0.2319\n",
      "Epoch 33/150\n",
      " - 3s - loss: 1.6261 - acc: 0.3776 - val_loss: 2.1145 - val_acc: 0.2174\n",
      "Epoch 34/150\n",
      " - 3s - loss: 1.6169 - acc: 0.3692 - val_loss: 2.0400 - val_acc: 0.2319\n",
      "Epoch 35/150\n",
      " - 3s - loss: 1.6288 - acc: 0.3692 - val_loss: 1.9480 - val_acc: 0.2754\n",
      "Epoch 36/150\n",
      " - 3s - loss: 1.6417 - acc: 0.3593 - val_loss: 1.9689 - val_acc: 0.2754\n",
      "Epoch 37/150\n",
      " - 3s - loss: 1.6030 - acc: 0.3806 - val_loss: 1.8359 - val_acc: 0.2899\n",
      "Epoch 38/150\n",
      " - 3s - loss: 1.5896 - acc: 0.3898 - val_loss: 1.8246 - val_acc: 0.2754\n",
      "Epoch 39/150\n",
      " - 3s - loss: 1.5801 - acc: 0.3898 - val_loss: 1.9711 - val_acc: 0.2609\n",
      "Epoch 40/150\n",
      " - 3s - loss: 1.5649 - acc: 0.3822 - val_loss: 1.8969 - val_acc: 0.3333\n",
      "Epoch 41/150\n",
      " - 3s - loss: 1.5721 - acc: 0.3829 - val_loss: 1.8921 - val_acc: 0.2899\n",
      "Epoch 42/150\n",
      " - 3s - loss: 1.5426 - acc: 0.4020 - val_loss: 2.0294 - val_acc: 0.2899\n",
      "Epoch 43/150\n",
      " - 3s - loss: 1.5752 - acc: 0.3829 - val_loss: 2.0075 - val_acc: 0.3188\n",
      "Epoch 44/150\n",
      " - 3s - loss: 1.5344 - acc: 0.4035 - val_loss: 2.0262 - val_acc: 0.2319\n",
      "Epoch 45/150\n",
      " - 3s - loss: 1.5608 - acc: 0.3860 - val_loss: 1.9577 - val_acc: 0.2319\n",
      "Epoch 46/150\n",
      " - 3s - loss: 1.5219 - acc: 0.4096 - val_loss: 1.9284 - val_acc: 0.3043\n",
      "Epoch 47/150\n",
      " - 3s - loss: 1.5699 - acc: 0.3921 - val_loss: 2.0212 - val_acc: 0.2464\n",
      "Epoch 48/150\n",
      " - 3s - loss: 1.5426 - acc: 0.3890 - val_loss: 1.9432 - val_acc: 0.3333\n",
      "Epoch 49/150\n",
      " - 3s - loss: 1.5343 - acc: 0.4058 - val_loss: 2.0868 - val_acc: 0.2609\n",
      "Epoch 50/150\n",
      " - 3s - loss: 1.5082 - acc: 0.4081 - val_loss: 1.9619 - val_acc: 0.3333\n",
      "Epoch 51/150\n",
      " - 5s - loss: 1.5008 - acc: 0.4218 - val_loss: 1.9630 - val_acc: 0.2899\n",
      "Epoch 52/150\n",
      " - 3s - loss: 1.4989 - acc: 0.4195 - val_loss: 2.0300 - val_acc: 0.2899\n",
      "Epoch 53/150\n",
      " - 3s - loss: 1.5083 - acc: 0.4195 - val_loss: 2.0203 - val_acc: 0.2464\n",
      "Epoch 54/150\n",
      " - 3s - loss: 1.5257 - acc: 0.4119 - val_loss: 1.8432 - val_acc: 0.3333\n",
      "Epoch 55/150\n",
      " - 3s - loss: 1.5009 - acc: 0.4134 - val_loss: 1.8795 - val_acc: 0.2899\n",
      "Epoch 56/150\n",
      " - 3s - loss: 1.5153 - acc: 0.4020 - val_loss: 1.9914 - val_acc: 0.2754\n",
      "Epoch 57/150\n",
      " - 3s - loss: 1.4761 - acc: 0.4073 - val_loss: 1.9771 - val_acc: 0.2754\n",
      "Epoch 58/150\n",
      " - 4s - loss: 1.5142 - acc: 0.4005 - val_loss: 2.0484 - val_acc: 0.2609\n",
      "Epoch 59/150\n",
      " - 3s - loss: 1.4615 - acc: 0.4355 - val_loss: 1.9862 - val_acc: 0.2609\n",
      "Epoch 60/150\n",
      " - 5s - loss: 1.4777 - acc: 0.4264 - val_loss: 2.1046 - val_acc: 0.2464\n",
      "Epoch 61/150\n",
      " - 9s - loss: 1.4940 - acc: 0.4127 - val_loss: 2.0823 - val_acc: 0.3333\n",
      "Epoch 62/150\n",
      " - 8s - loss: 1.4428 - acc: 0.4264 - val_loss: 2.0376 - val_acc: 0.2174\n",
      "Epoch 63/150\n",
      " - 6s - loss: 1.4507 - acc: 0.4287 - val_loss: 1.9841 - val_acc: 0.3478\n",
      "Epoch 64/150\n",
      " - 4s - loss: 1.4525 - acc: 0.4363 - val_loss: 2.0102 - val_acc: 0.3043\n",
      "Epoch 65/150\n",
      " - 11s - loss: 1.4109 - acc: 0.4600 - val_loss: 2.1418 - val_acc: 0.2319\n",
      "Epoch 66/150\n",
      " - 31s - loss: 1.4679 - acc: 0.4233 - val_loss: 1.9415 - val_acc: 0.2899\n",
      "Epoch 67/150\n",
      " - 18s - loss: 1.4159 - acc: 0.4394 - val_loss: 1.9172 - val_acc: 0.2899\n",
      "Epoch 68/150\n",
      " - 3s - loss: 1.4262 - acc: 0.4416 - val_loss: 1.9704 - val_acc: 0.3043\n",
      "Epoch 69/150\n",
      " - 3s - loss: 1.4164 - acc: 0.4264 - val_loss: 1.9555 - val_acc: 0.3478\n",
      "Epoch 70/150\n",
      " - 3s - loss: 1.3824 - acc: 0.4554 - val_loss: 1.9508 - val_acc: 0.3188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/150\n",
      " - 3s - loss: 1.4206 - acc: 0.4424 - val_loss: 2.1613 - val_acc: 0.2754\n",
      "Epoch 72/150\n",
      " - 3s - loss: 1.4132 - acc: 0.4287 - val_loss: 2.0416 - val_acc: 0.2754\n",
      "Epoch 73/150\n",
      " - 3s - loss: 1.4050 - acc: 0.4310 - val_loss: 1.9253 - val_acc: 0.3768\n",
      "Epoch 74/150\n",
      " - 3s - loss: 1.4122 - acc: 0.4500 - val_loss: 2.0414 - val_acc: 0.3043\n",
      "Epoch 75/150\n",
      " - 3s - loss: 1.3898 - acc: 0.4592 - val_loss: 2.0836 - val_acc: 0.3188\n",
      "Epoch 76/150\n",
      " - 3s - loss: 1.3932 - acc: 0.4333 - val_loss: 2.1376 - val_acc: 0.2899\n",
      "Epoch 77/150\n",
      " - 3s - loss: 1.4026 - acc: 0.4302 - val_loss: 1.9808 - val_acc: 0.3478\n",
      "Epoch 78/150\n",
      " - 3s - loss: 1.3831 - acc: 0.4500 - val_loss: 2.1053 - val_acc: 0.2899\n",
      "Epoch 79/150\n",
      " - 3s - loss: 1.3811 - acc: 0.4630 - val_loss: 1.8913 - val_acc: 0.3768\n",
      "Epoch 80/150\n",
      " - 3s - loss: 1.3699 - acc: 0.4607 - val_loss: 1.8980 - val_acc: 0.3768\n",
      "Epoch 81/150\n",
      " - 3s - loss: 1.3464 - acc: 0.4622 - val_loss: 1.9354 - val_acc: 0.4058\n",
      "Epoch 82/150\n",
      " - 3s - loss: 1.3747 - acc: 0.4676 - val_loss: 1.9278 - val_acc: 0.3623\n",
      "Epoch 83/150\n",
      " - 3s - loss: 1.3521 - acc: 0.4546 - val_loss: 1.9187 - val_acc: 0.3768\n",
      "Epoch 84/150\n",
      " - 3s - loss: 1.3095 - acc: 0.4882 - val_loss: 2.2140 - val_acc: 0.3188\n",
      "Epoch 85/150\n",
      " - 4s - loss: 1.3588 - acc: 0.4691 - val_loss: 1.9768 - val_acc: 0.3478\n",
      "Epoch 86/150\n",
      " - 3s - loss: 1.3186 - acc: 0.4661 - val_loss: 2.0187 - val_acc: 0.3623\n",
      "Epoch 87/150\n",
      " - 3s - loss: 1.3432 - acc: 0.4691 - val_loss: 2.1057 - val_acc: 0.2899\n",
      "Epoch 88/150\n",
      " - 3s - loss: 1.3593 - acc: 0.4638 - val_loss: 2.0614 - val_acc: 0.3188\n",
      "Epoch 89/150\n",
      " - 3s - loss: 1.3226 - acc: 0.4859 - val_loss: 2.1942 - val_acc: 0.3333\n",
      "Epoch 90/150\n",
      " - 3s - loss: 1.3867 - acc: 0.4424 - val_loss: 2.1187 - val_acc: 0.3188\n",
      "Epoch 91/150\n",
      " - 3s - loss: 1.3298 - acc: 0.4630 - val_loss: 2.0825 - val_acc: 0.3623\n",
      "Epoch 92/150\n",
      " - 3s - loss: 1.2963 - acc: 0.4836 - val_loss: 2.0199 - val_acc: 0.3913\n",
      "Epoch 93/150\n",
      " - 3s - loss: 1.2829 - acc: 0.4645 - val_loss: 2.0237 - val_acc: 0.3478\n",
      "Epoch 94/150\n",
      " - 3s - loss: 1.2852 - acc: 0.4790 - val_loss: 1.9937 - val_acc: 0.3768\n",
      "Epoch 95/150\n",
      " - 3s - loss: 1.3538 - acc: 0.4439 - val_loss: 2.2072 - val_acc: 0.3333\n",
      "Epoch 96/150\n",
      " - 3s - loss: 1.2918 - acc: 0.4912 - val_loss: 2.0537 - val_acc: 0.3913\n",
      "Epoch 97/150\n",
      " - 3s - loss: 1.2967 - acc: 0.4767 - val_loss: 2.1796 - val_acc: 0.2754\n",
      "Epoch 98/150\n",
      " - 3s - loss: 1.2979 - acc: 0.4744 - val_loss: 2.2418 - val_acc: 0.3333\n",
      "Epoch 99/150\n",
      " - 3s - loss: 1.2885 - acc: 0.4775 - val_loss: 2.0828 - val_acc: 0.3768\n",
      "Epoch 100/150\n",
      " - 3s - loss: 1.2558 - acc: 0.4920 - val_loss: 2.0884 - val_acc: 0.3913\n",
      "Epoch 101/150\n",
      " - 3s - loss: 1.3275 - acc: 0.4851 - val_loss: 2.1052 - val_acc: 0.3043\n",
      "Epoch 102/150\n",
      " - 3s - loss: 1.3151 - acc: 0.4600 - val_loss: 2.1282 - val_acc: 0.3333\n",
      "Epoch 103/150\n",
      " - 3s - loss: 1.2335 - acc: 0.5042 - val_loss: 2.1772 - val_acc: 0.3333\n",
      "Epoch 104/150\n",
      " - 3s - loss: 1.2420 - acc: 0.5042 - val_loss: 2.1876 - val_acc: 0.4058\n",
      "Epoch 105/150\n",
      " - 3s - loss: 1.2613 - acc: 0.4950 - val_loss: 2.0331 - val_acc: 0.3478\n",
      "Epoch 106/150\n",
      " - 3s - loss: 1.2740 - acc: 0.4874 - val_loss: 2.0996 - val_acc: 0.3478\n",
      "Epoch 107/150\n",
      " - 3s - loss: 1.3450 - acc: 0.4653 - val_loss: 2.0390 - val_acc: 0.3913\n",
      "Epoch 108/150\n",
      " - 3s - loss: 1.2124 - acc: 0.5210 - val_loss: 2.0759 - val_acc: 0.3333\n",
      "Epoch 109/150\n",
      " - 3s - loss: 1.2279 - acc: 0.5172 - val_loss: 2.0523 - val_acc: 0.3768\n",
      "Epoch 110/150\n",
      " - 3s - loss: 1.3625 - acc: 0.4561 - val_loss: 1.8869 - val_acc: 0.4203\n",
      "Epoch 111/150\n",
      " - 21s - loss: 1.2992 - acc: 0.4867 - val_loss: 2.0423 - val_acc: 0.4058\n",
      "Epoch 112/150\n",
      " - 31s - loss: 1.2430 - acc: 0.5019 - val_loss: 2.1091 - val_acc: 0.3333\n",
      "Epoch 113/150\n",
      " - 3s - loss: 1.2493 - acc: 0.4928 - val_loss: 1.9823 - val_acc: 0.4058\n",
      "Epoch 114/150\n",
      " - 3s - loss: 1.2360 - acc: 0.4973 - val_loss: 2.0245 - val_acc: 0.3768\n",
      "Epoch 115/150\n",
      " - 3s - loss: 1.2121 - acc: 0.5179 - val_loss: 2.1190 - val_acc: 0.3623\n",
      "Epoch 116/150\n",
      " - 3s - loss: 1.2688 - acc: 0.4928 - val_loss: 2.0856 - val_acc: 0.3768\n",
      "Epoch 117/150\n",
      " - 3s - loss: 1.2216 - acc: 0.5057 - val_loss: 2.0388 - val_acc: 0.4783\n",
      "Epoch 118/150\n",
      " - 3s - loss: 1.1895 - acc: 0.5149 - val_loss: 2.1381 - val_acc: 0.3913\n",
      "Epoch 119/150\n",
      " - 3s - loss: 1.2170 - acc: 0.5118 - val_loss: 2.0784 - val_acc: 0.4058\n",
      "Epoch 120/150\n",
      " - 3s - loss: 1.2151 - acc: 0.5240 - val_loss: 2.0773 - val_acc: 0.4203\n",
      "Epoch 121/150\n",
      " - 3s - loss: 1.2061 - acc: 0.5256 - val_loss: 2.1103 - val_acc: 0.4928\n",
      "Epoch 122/150\n",
      " - 3s - loss: 1.2518 - acc: 0.4920 - val_loss: 2.3075 - val_acc: 0.3333\n",
      "Epoch 123/150\n",
      " - 3s - loss: 1.2396 - acc: 0.4943 - val_loss: 2.1092 - val_acc: 0.4058\n",
      "Epoch 124/150\n",
      " - 3s - loss: 1.2291 - acc: 0.4928 - val_loss: 2.0468 - val_acc: 0.4058\n",
      "Epoch 125/150\n",
      " - 3s - loss: 1.2136 - acc: 0.5080 - val_loss: 2.2631 - val_acc: 0.3478\n",
      "Epoch 126/150\n",
      " - 3s - loss: 1.1925 - acc: 0.5118 - val_loss: 1.9996 - val_acc: 0.4493\n",
      "Epoch 127/150\n",
      " - 3s - loss: 1.2369 - acc: 0.5164 - val_loss: 2.1320 - val_acc: 0.3623\n",
      "Epoch 128/150\n",
      " - 3s - loss: 1.2167 - acc: 0.5233 - val_loss: 2.2099 - val_acc: 0.3043\n",
      "Epoch 129/150\n",
      " - 3s - loss: 1.2041 - acc: 0.5202 - val_loss: 1.9765 - val_acc: 0.3768\n",
      "Epoch 130/150\n",
      " - 3s - loss: 1.1888 - acc: 0.5278 - val_loss: 2.1132 - val_acc: 0.3768\n",
      "Epoch 131/150\n",
      " - 3s - loss: 1.1708 - acc: 0.5210 - val_loss: 2.0347 - val_acc: 0.4058\n",
      "Epoch 132/150\n",
      " - 3s - loss: 1.1677 - acc: 0.5172 - val_loss: 2.2266 - val_acc: 0.4203\n",
      "Epoch 133/150\n",
      " - 3s - loss: 1.1674 - acc: 0.5271 - val_loss: 2.2580 - val_acc: 0.4348\n",
      "Epoch 134/150\n",
      " - 3s - loss: 1.2434 - acc: 0.4981 - val_loss: 2.2061 - val_acc: 0.3623\n",
      "Epoch 135/150\n",
      " - 3s - loss: 1.1767 - acc: 0.5233 - val_loss: 1.9536 - val_acc: 0.3768\n",
      "Epoch 136/150\n",
      " - 3s - loss: 1.1412 - acc: 0.5332 - val_loss: 2.1549 - val_acc: 0.4493\n",
      "Epoch 137/150\n",
      " - 3s - loss: 1.1214 - acc: 0.5347 - val_loss: 1.9492 - val_acc: 0.4783\n",
      "Epoch 138/150\n",
      " - 3s - loss: 1.1486 - acc: 0.5248 - val_loss: 1.9400 - val_acc: 0.4348\n",
      "Epoch 139/150\n",
      " - 3s - loss: 1.1974 - acc: 0.5072 - val_loss: 2.1101 - val_acc: 0.3333\n",
      "Epoch 140/150\n",
      " - 3s - loss: 1.1518 - acc: 0.5195 - val_loss: 1.9798 - val_acc: 0.4203\n",
      "Epoch 141/150\n",
      " - 3s - loss: 1.1598 - acc: 0.5271 - val_loss: 2.2892 - val_acc: 0.3333\n",
      "Epoch 142/150\n",
      " - 3s - loss: 1.2207 - acc: 0.4996 - val_loss: 2.1277 - val_acc: 0.3768\n",
      "Epoch 143/150\n",
      " - 3s - loss: 1.1861 - acc: 0.5103 - val_loss: 1.9581 - val_acc: 0.4783\n",
      "Epoch 144/150\n",
      " - 3s - loss: 1.1414 - acc: 0.5355 - val_loss: 2.1246 - val_acc: 0.3478\n",
      "Epoch 145/150\n",
      " - 3s - loss: 1.2157 - acc: 0.5095 - val_loss: 1.9659 - val_acc: 0.3043\n",
      "Epoch 146/150\n",
      " - 3s - loss: 1.1527 - acc: 0.5156 - val_loss: 2.0512 - val_acc: 0.3913\n",
      "Epoch 147/150\n",
      " - 3s - loss: 1.1474 - acc: 0.5294 - val_loss: 2.0041 - val_acc: 0.4638\n",
      "Epoch 148/150\n",
      " - 3s - loss: 1.1979 - acc: 0.5172 - val_loss: 2.0552 - val_acc: 0.3913\n",
      "Epoch 149/150\n",
      " - 3s - loss: 1.1729 - acc: 0.5065 - val_loss: 2.1910 - val_acc: 0.3478\n",
      "Epoch 150/150\n",
      " - 3s - loss: 1.1235 - acc: 0.5332 - val_loss: 1.9970 - val_acc: 0.4203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x52676c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_traincnn,y_train,validation_data=(x_testcnn,y_test),verbose=2,epochs=150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################### PREDICTION ON TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 2.2054 \n",
      "Test acc = 0.3913 \n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(x_testcnn)\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x_testcnn, y_test,verbose=0)\n",
    "\n",
    "print('Test loss = {:.4f} '.format(loss))\n",
    "print('Test acc = {:.4f} '.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############# SAVING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open(\"C:\\\\Users\\\\dbda\\\\Desktop\\\\project\\\\TSNE_CNN.pkl\", 'wb'))\n",
    "print(\"Model Saved!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################### Prediction on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    x_test,y_test=[],[]\n",
    "    \n",
    "    file=\"F:\\\\speech_project\\\\UnSeenSet\\\\03-01-02-01-02-01-18.wav\"\n",
    "    emotion=emotions[file.split(\"-\")[2]]\n",
    "    feature=extract_feature(file, mfcc=True, chroma=True,spectral_centroid=True,spectral_bandwidth=True,\n",
    "                            spectral_rolloff=True,spectral_contrast=True,rms=True,spectral_flatness=True)\n",
    "    \n",
    "    x_test.append(feature)\n",
    "    y_test.append(emotion)\n",
    "    # Create scaler: scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X=scaler.fit_transform(x)\n",
    "    X=pd.DataFrame(X)\n",
    "    ############ \n",
    "    tsne = TSNE(learning_rate=200,random_state=2019)\n",
    "    # Apply fit_transform to samples: tsne_features\n",
    "    tsne_features = tsne.fit_transform(X)\n",
    "    return x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data,y_test_data=load_test_data()\n",
    "print(y_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############## RESHAPING PREDICTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = np.expand_dims(X_test_data, axis=2)\n",
    "print(x_traincnn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########### LOADING SAVED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "loaded_model = pickle.load(open(\"C:\\\\Users\\\\dbda\\\\Desktop\\\\project\\\\TSNE_CNN.pkl\", 'rb'))\n",
    "result = loaded_model.predict(X_test_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(le.inverse_transform(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
