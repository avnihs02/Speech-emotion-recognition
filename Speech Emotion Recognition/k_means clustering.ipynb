{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing \n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotions in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, mfcc, chroma,spectral_centroid,spectral_bandwidth,spectral_rolloff,spectral_contrast,rms,spectral_flatness):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "            \n",
    "            \n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))             \n",
    "           \n",
    "            \n",
    "        if spectral_centroid:\n",
    "            spectral_centroid=np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate))\n",
    "            result=np.hstack((result, spectral_centroid)) \n",
    "        \n",
    "        if spectral_bandwidth:\n",
    "           spectral_bandwidth=np.mean(librosa.feature.spectral_bandwidth(y=X, sr=sample_rate).T)\n",
    "#           print(spectral_bandwidth)\n",
    "           result=np.hstack((result, spectral_bandwidth)) \n",
    "           \n",
    "        if spectral_rolloff:\n",
    "           spectral_rolloff=np.mean(librosa.feature.spectral_rolloff(y=X, sr=sample_rate).T)\n",
    "#           print(spectral_rolloff)\n",
    "           result=np.hstack((result, spectral_rolloff))\n",
    "        \n",
    "        if spectral_contrast:\n",
    "           spectral_contrast=np.mean(librosa.feature.spectral_contrast(y=X, sr=sample_rate))\n",
    "           result=np.hstack((result, spectral_contrast))\n",
    "           \n",
    "        if rms:\n",
    "           rms=np.mean(librosa.feature.rms(y=X).T,axis=0)\n",
    "           result=np.hstack((result, rms))\n",
    "           \n",
    "        if spectral_flatness:\n",
    "           spectral_flatness=np.mean(librosa.feature.spectral_flatness(y=X))\n",
    "           result=np.hstack((result, spectral_flatness))\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature extraction from audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### feature extraction by calling the files ############################\n",
    "\n",
    "def load_data():\n",
    "    X,y=[],[]\n",
    "    for file in glob.glob(\"D:\\\\DBDA\\\\speech-emotion-recognition-ravdess-data\\\\Actor_*\\\\*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True,spectral_centroid=True,spectral_bandwidth=True,spectral_rolloff=True,spectral_contrast=True,rms=True,spectral_flatness=True)\n",
    "        X.append(feature)\n",
    "        y.append(emotion)\n",
    "        \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "X_audio,y_emotions=load_data()\n",
    "\n",
    "features=[]\n",
    "for i in range(1,59) :\n",
    "    features.append(\"feat\"+str(i))    \n",
    "\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y1=le.fit_transform(y_emotions)\n",
    "\n",
    "\n",
    "X1=pd.DataFrame(X_audio,columns=features)\n",
    "y=pd.DataFrame(y1,columns=[\"emotions\"])\n",
    "X=X1.drop([\"feat1\"],axis=1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.1, random_state=2019,stratify=y) \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train_scaled=scaler.fit_transform(x_train)\n",
    "x_train_scaled = pd.DataFrame(x_train_scaled,index=x_train.index,columns=x_train.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scree Plot to decide number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3xV9f3H8dcnAwgzQABJQMKMMhQw4mIVrTgBaW3tUKv+HLVqHdU62p9a94/WVltba9WqVWlRWU7EBYpFQEXZQ3bCiOwRAkk+vz/uiUYMJIGbnHtv3s/HI4/cfO85934O475zzvd7vl9zd0RERA4kKewCREQk9iksRESkUgoLERGplMJCREQqpbAQEZFKKSxERKRSCguROGJm2WbmZpYSdi1StygspE4zs/5m9qGZbTWzTWY2zcyODbmmwWZWamY7zGy7mS0ys4sO4nXuMLNna6JGqXv024nUWWbWFHgF+DkwBqgHDACKqvk6Ke5eHOXy8t29nZkZMBx40cw+AnZF+X1EqkRnFlKXdQNw99HuXuLuhe7+prt/XraBmV1qZguC3/Dnm1nfoH2Fmf3azD4HdppZipllmtlLZlZgZsvN7Jpyr5NkZjeb2RdmttHMxphZi8oK9IjxwGag+77PB+85MTgrWmpmlwbtpwG3Aj8MzlA+O8Q/K6njFBZSly0GSszsaTM73cyal3/SzM4F7gAuAJoCw4CN5Tb5EXAmkA6UAi8DnwFZwMnAtWY2NNj2GmAEMAjIJPLh/0hlBQYhc07wHnMq2GQ0sCZ4ze8D95rZye7+BnAv8B93b+zuR1f2XiIHorCQOsvdtwH9AQf+ARQEv6W3CTb5H+D/3H1m8Bv+UndfWe4lHnb31e5eCBwLtHL337n7HndfFrzmecG2lwO3ufsady8iEkLfP0BHdaaZbQG+BG4Hznf3ReU3MLP2Qf2/dvfd7j4beBw4/1D+XEQqoj4LqdPcfQHwMwAzOwJ4FvgTkbOG9sAXB9h9dbnHHfj6A75MMvB+uefHmVlpuedLgDZAXgWvne/u7SopPxPY5O7by7WtBHIr2U+k2hQWIgF3X2hmTxE5C4BIGHQ+0C7lHq8Glrt71/1suxq42N2nHXKhX8sHWphZk3KBcThfh4+mlJao0WUoqbPM7Agzu8HM2gU/tydyRjE92ORx4FdmdoxFdDGzDvt5uRnAtqDTO83Mks2sZ7lhuI8C95Ttb2atzGz4odTv7quBD4H7zKyBmR0FXAI8F2yyHsg2M/0/l0Omf0RSl20HjgM+MrOdREJiLnADgLu/ANwDPB9sOx6ocASTu5cAZwO9geVE+hoeB5oFmzwETATeNLPtwXsdF4Vj+BGQTeQsYxxwu7tPDp57Ifi+0cw+icJ7SR1mWvxIREQqozMLERGplMJCREQqpbAQEZFKKSxERKRSCXmfRUZGhmdnZ4ddhohIXPn444+/dPdWFT2XkGGRnZ3NrFmzwi5DRCSumNnK/T2ny1AiIlIphYWIiFRKYSEiIpVSWIiISKUUFiIiUqmEHA11sMZ/mseoSYvI31JIZnoaNw7NYUSfrLDLEhEJncIiMP7TPG4ZO4fCvSUA5G0p5JaxkVUsFRgiUtfpMlRg1KRFXwVFmcK9JYyatGg/e4iI1B0Ki0D+lsJqtYuI1CUKi0Bmelq12kVE6hKFReDGoTmkpSZ/o61BahI3Ds0JqSIRkdihDu5AWSd22WgoB3I7NFfntogICotvGNEn66twuGPiPJ7+7wpmr95C7/bp4RYmIhIyXYbajxtO7UbrJvW5dewciktKwy5HRCRUCov9aNIglTvO7sH8tdt46sMVYZcjIhIqhcUBnNbzMIYc0ZoHJy8mT0NoRaQOU1gcgJlx57AeuMPtE+aFXY6ISGgUFpVo36Ih157SlbcWrGfSvHVhlyMiEgqFRRVc3L8jRxzWhDsmzmNHUXHY5YiI1DqFRRWkJidxzzm9WLdtNw++uTjsckREap3CooqO6dCcH/c7nKc+XM7cvK1hlyMiUqsUFtVw02lH0KJRfW4dN4eSUg+7HBGRWqOwqIZmaan89qwj+XzNVp6dvjLsckREao3CopqGHZ3JgK4ZjJq0iHVbd4ddjohIrVBYVJOZcfeInuwtKeV3r+jeCxGpGxQWB6FDy0ZcPaQLr81ZxzsL14ddjohIjauxsDCzJ81sg5nNLdd2l5l9bmazzexNM8sM2s3MHjazpcHzfcvtc6GZLQm+LqypeqvrsoGd6dK6Mb8dP49de3TvhYgktpo8s3gKOG2ftlHufpS79wZeAf43aD8d6Bp8XQb8DcDMWgC3A8cB/YDbzax5DdZcZfVSkrj3nF7kbSnkobeXhF2OiEiNqrGwcPepwKZ92raV+7ERUDb+dDjwjEdMB9LNrC0wFJjs7pvcfTMwmW8HUGj6dWzBD3Lb8cT7y1m4blvlO4iIxKla77Mws3vMbDXwE74+s8gCVpfbbE3Qtr/2mHHL6UfSNC2VW8bOoVT3XohIgqr1sHD329y9PfAccFXQbBVteoD2bzGzy8xslpnNKigoiE6xVdC8UT1uO+NIPl21hdEzV9Xa+4qI1KYwR0M9D3wveLwGaF/uuXZA/gHav8XdH3P3XHfPbdWqVQ2Uu38j+2ZxQqeWPPD6Qgq2F9Xqe4uI1IZaDQsz61rux2HAwuDxROCCYFTU8cBWd18LTAJONbPmQcf2qUFbTDEz7j6nJ7v3lnL3q/PDLkdEJOpSauqFzWw0MBjIMLM1REY1nWFmOUApsBK4Itj8NeAMYCmwC7gIwN03mdldwMxgu9+5+zc6zWNF51aN+fngzjz09hK+17cdA7vV7tmNiEhNMvfE65TNzc31WbNm1fr77t5bwukPvU+pO5OuHUiD1ORar0FE5GCZ2cfunlvRc7qDO4oapCZzz4ierNy4i0feXRp2OSIiUaOwiLITu2Qwsk8Wj075gqUbtoddjohIVCgsasCtZx5Jw3op3DpuLol4mU9E6h6FRQ3IaFyfW04/ghnLN/HCx2vCLkdE5JApLGrID3Lbc2x2c+59bQEbd+jeCxGJbwqLGpKUZNxzTi927C7m3tcWVr6DiEgMU1jUoG5tmnDZwE689Mka/vvFxrDLERE5aAqLGnb1kK60b5HGbePnUFRcEnY5IiIHRWFRw9LqJXPX8J4sK9jJo+8tC7scEZGDorCoBYNzWnPWUW155L2lLP9yZ9jliIhUm8KilvzvWd2pn5zEb8bP0b0XIhJ3FBa1pHXTBtx0+hFMW7qR8bPzwi5HRKRaFBa16Cf9Dqd3+3TufmUBW3btCbscEZEqU1jUoqQk495zerGlcC8PvKF7L0Qkfigsaln3zKZc0r8jo2esZuaKmFyaQ0TkWxQWIbj2lK5kpadx27g57CkuDbscEZFKKSxC0LBeCncO68Hi9Tt4/APdeyEisU9hEZJTurdhaI82PPz2ElZt3BV2OSIiB6SwCNEdw3qQbMZvJ2jdCxGJbQqLELVtlsYNp+YwZXEBr85ZG3Y5IiL7pbAI2YUnZtMzqyl3vjyfbbv3hl2OiEiFFBYhS04y7jvnKDbuKGLUG4vCLkdEpEIKixjQq10zLjghm2c/Wsns1VvCLkdE5FsUFjHihlO70bpJfW4ZO4fiEt17ISKxRWERI5o0SOXOYT1YsHYb/5y2IuxyRES+QWERQ4b2OIyTj2jNg5MXk7elMOxyRES+orCIIWbGncN7AHC77r0QkRiisIgx7Zo35NpTuvLWgg1Mmrc+7HJERACFRUy6uH9HjjisCXdMnMeOouKwyxERUVjEotTkJO4d2Yv123fz4JuLwy5HRERhEav6Ht6cH/c7nKc+XM7cvK1hlyMidZzCIobddNoRtGhUn1vHzaGkVJ3dIhIehUUMa5aWyv+e3Z3P12zlX/9dEXY5IlKHKSxi3NlHtWVA1wx+/+Zi1m3dHXY5IlJHKSxinJlx94ie7C0p5c6X54VdjojUUQqLONChZSOuObkrr89dxzsLde+FiNQ+hUWcuHRAJ7q2bsxvx89j1x7deyEitavGwsLMnjSzDWY2t1zbKDNbaGafm9k4M0sv99wtZrbUzBaZ2dBy7acFbUvN7OaaqjfW1UtJ4p5zepG3pZCH3loSdjkiUsfU5JnFU8Bp+7RNBnq6+1HAYuAWADPrDpwH9Aj2+auZJZtZMvAIcDrQHfhRsG2d1K9jC36Y257HP1jOgrXbwi5HROqQGgsLd58KbNqn7U13L7uGMh1oFzweDvzb3YvcfTmwFOgXfC1192Xuvgf4d7BtnXXz6UfQLC2VW8fNoVT3XohILQmzz+Ji4PXgcRawutxza4K2/bV/i5ldZmazzGxWQUFBDZQbG5o3qsdtZxzJp6u2MHrmqrDLEZE6IpSwMLPbgGLgubKmCjbzA7R/u9H9MXfPdffcVq1aRafQGDWybxYndGrJ/a8vZMN23XshIjWv1sPCzC4EzgJ+4l8v2LAGaF9us3ZA/gHa6zQz4+5zelK0t5S7X1kQdjkiUgfUaliY2WnAr4Fh7r6r3FMTgfPMrL6ZdQS6AjOAmUBXM+toZvWIdIJPrM2aY1XnVo35+eDOTPwsn6mLE/eym4jEhpocOjsa+C+QY2ZrzOwS4C9AE2Cymc02s0cB3H0eMAaYD7wB/MLdS4LO8KuAScACYEywrQA/H9yZThmN+M34uezeWxJ2OSKSwCwRl+7Mzc31WbNmhV1Grfjwiy/58T8+4qrvdOFXQ3PCLkdE4piZfezuuRU9pzu449yJnTMY2SeLv0/9giXrt4ddjogkKIVFArj1zCNpWC+F28bN1b0XIlIjFBYJIKNxfW494whmrNjEix+vCbscEUlACosEce4x7Tk2uzn3vr6AjTuKwi5HRBKMwiJBJCUZ95zTix27i7n3tYVhlyMiCUZhkUC6tWnC5YM68dIna/jwiy/DLkdEEkhK2AVIdF09pCujZ6zigidmUFLqZKancePQHEb0qXBKLRGRKlFYJJg35q5jx+4SioNRUXlbCrll7BwABYaIHDRdhkowoyYtYk9J6TfaCveWMGrSopAqEpFEoLBIMPlbCqvVLiJSFQqLBJOZnlZhuwN/nLyYomLNISUi1aewSDA3Ds0hLTX5G20NUpPoe3g6D729hLMe/oCPV24OqToRiVcKiwQzok8W943sRVZ6GgZkpadx/8ijGHvlSTz5s1x2FhXz/Uc/5I6J89hRVFzp64mIQDVmnTWzM4EeQIOyNnf/XQ3VdUjq0qyz1bWjqJhRbyzkmekradu0Afec04vvHNE67LJEJAYc8qyzwboTPwSuJrLU6blAh6hVKLWmcf0U7hzekxevOIGG9VO46KmZ/PLfn2qKEBE5oKpehjrR3S8ANrv7ncAJfHO5U4kzx3RowavX9OeXJ3fltTlrOeXBKYz7dA2JuL6JiBy6qoZF2bjLXWaWCewFOtZMSVJb6qckc913u/HqNQPIzmjEdf/5jJ/9cyZrNu+qfGcRqVOqGhavmFk6MAr4BFgB/LumipLa1a1NE1684kTuOLs7M1ds4tQ/TuXJD5ZTorUxRCRQ7WVVzaw+0MDdt9ZMSYdOHdwHb83mXfxm/FzeW1RA7/bpPPC9o8g5rEnYZYlILThQB/cBw8LMhrj7O2Y2sqLn3X1slGqMKoXFoXF3JszO586XI8Nrfz6oM78Y0oX6KcmV7ywicetAYVHZRIKDgHeAsyt4zoGYDAs5NGbGiD5ZDOiawd2vLuDhd5by6py1PPC9o8jNbhF2eSISgipdhjKzju6+vLK2WKEzi+h6b9EGbhs3l7wthZx/fAduOi2HJg1Swy5LRKLskO+zAF6qoO3Fgy9J4sngnNa8ed1AfnZiNs9+tJJT/ziVtxesD7ssEalFB7wMZWZHELlru9k+/RZNKXcntyS+RvVTuGNYD4b1zuTmlz7nkqdncfbRmdx+dncyGtcPuzwRqWGV9VnkAGcB6Xyz32I7cGlNFSWxq+/hzXnl6gH87b0v+Mu7S3h/SQG/ObM73+ubhZmFXZ6I1JBK+yzMLBn4tbvfWzslHTr1WdSOJeu3c/PYOXy8cjMDumZw7zm9aN+iYdhlichBOqQ+C3cvAb4b9aok7nVt04QXLj+B3w3vwScrN3PqH6fy+PvLdDOfSAKqagf3h2b2FzMbYGZ9y75qtDKJC0lJxgUnZDP5+kGc0Lkld7+6gJF/ncaCtdvCLk1EoqiqQ2ffraDZ3X1I9Es6dLoMFQ535+XP13LnxHlsLdzLFYM6c9WQLjRI1c18IvHgoO/gjlcKi3Bt3rmHu16dz9hP8ujUqhH3jzyKfh11M59IrIvGehZtzOwJM3s9+Lm7mV0SzSIlcTRvVI8Hf9Cbpy/uR9HeUn7w9/9y27g5bNu9N+zSROQgVbXP4ilgEpAZ/LwYuLYmCpLEMahbK968biCX9O/I6BmrOPXBqUyer5v5ROJRVcMiw93HAKUA7l4MlNRYVZIwGtVP4bdndWfslSfRLC2VS5+ZxS+e+4SC7VqZTySeVDUsdppZSyKTB2JmxwMxO0W5xJ7e7dN5+er+/OrUbkyev55THpzCmFmrtTKfSJyoalhcD0wEOpvZNOAZIutxi1RZvZQkrhrSldd+OYBubRpz04uf89MnPmLlxp1hlyYilajyaCgzSyEy/YcBi9w9ZnsrNRoq9pWWOs/NWMUDry+kuLSU67/bjYtP6khKclV/fxGRaIvGrLMA/YCjgb7Aj8zsgmgUJ3VTUpJx/vEdmHz9QPp3yeDe1xZyzl8/ZF6+rm6KxKKqDp39F/B7oD9wbPBVYfqU2+dJM9tgZnPLtZ1rZvPMrNTMcvfZ/hYzW2pmi8xsaLn204K2pWZ2czWOTeJA22Zp/OOCXP7y4z6s3VrIsL9M44E3FrJ7r8ZPiMSSymadLZMLdPfq9UY+BfyFSP9GmbnASODv5Tc0s+7AeUSmQ88E3jKzbsHTjxCZm2oNMNPMJrr7/GrUITHOzDjrqEz6d4mszPe3977gjbnruG9kL9Zt3c2oSYvI31JIZnoaNw7NYUSfrLBLFqlzqhoWc4HDgLVVfWF3n2pm2fu0LQAqmsp6OPBvdy8ClpvZUiKXvQCWuvuyYL9/B9sqLBJQesN6/P7coxnRO4tbxn3OeY9NJznJvpqYMG9LIbeMnQOgwBCpZVW+zwKYb2aTzGxi2VcU68gCVpf7eU3Qtr/2bzGzy8xslpnNKigoiGJpUtv6d81g0rUDaVw/+Vsz2BbuLWHUpEUhVSZSd1X1zOKOmiyCyAirfTkVh1mFl8Lc/THgMYiMhopeaRKGhvVS2FlUcb9F/pbCWq5GRKoUFu4+pYbrWAO0L/dzOyA/eLy/dklwmelp5FUQDPVTk1j+5U46ZjQKoSqRuumAl6HMbLuZbavga7uZRXPBgonAeWZW38w6Al2BGcBMoKuZdTSzekQ6waN5+Uti2I1Dc0jbZ3rzlCSjpMT57oNTuGPiPDbu0LQhIrXhgGcW7t7kYF/YzEYDg4EMM1sD3A5sAv4MtAJeNbPZ7j7U3eeZ2RgiHdfFwC+CFfows6uITGKYDDzp7vMOtiaJL2Wd2PuOhjqxc0v++NYSnvnvCl76eA1XDO7MxSd1JK2e1s0QqSlaz0Li1tIN27n/9YW8tWADhzVtwA2ndmNk33YkJ1XUBSYilYnWHdwiMaVL6yY8fuGx/Puy42nTtD43vvg5Zz78PlMWF2iCQpEoU1hI3Du+U0vG/+Ik/vyjPuzcU8yFT87g/CdmaOoQkShSWEhCMDPOPjqTt64fxG/P6s7c/K2c9ecPuP4/syscUSUi1aM+C0lIWwv38tf3lvLPaSsAuOikbK4c3IVmaanhFiYSww7UZ6GwkISWt6WQP0xaxLjZeTRLS+XqIV356fGHUz9FI6dE9qUObqmzstLTePCHvXn5qv70zGzGXa/M55QHp/DyZ/nqBBepBoWF1Ak9s5rxr0v68fTF/WhUL4WrR3/KiEem8dGyjWGXJhIXFBZSZ5gZg7q14tVrBjDq+0exflsRP3xsOv/z9EyWbtgednkiMU1hIXVOcpJxbm573v3VYG4cmsP0ZZs49Y9TuWXsHDZs3x12eSIxSR3cUudt3FHEn99ZyrPTV1IvJYlLB3TisoGdaFS/qpMyiyQGjYYSqYIVX+7k/yYt5LU568hoXJ/rvtuVH+a2JyVZJ+BSN2g0lEgVZGc04q8/OYaxV55IdsuG3DZuLkP/NJXJ89dr5JTUeQoLkX30Pbw5L1xxAn8//xjc4dJnZvHDx6Yze/WWsEsTCY3CQqQCZsbQHocx6bqB3DWiJ8sKdjDikWlc9fwnrNy4M+zyRGqd+ixEqmBHUTGPTfmCf7y/nOLSUn56fAeuGdKV5o3qhV2aSNSog1skStZv280fJy9mzKzVNKqfwpWDu3DRSdk0SNX0IRL/1MEtEiVtmjbg/u8dxRvXDqRfdgseeGMhQ37/Hi99vIbS0sT7xUukjMJC5CB0a9OEJ352LM9fehwtG9fnhhc+46w/f8D7SwrCLk2kRigsRA7BiZ0zmPCLk3jovN5s272X85+YwQVPzmB+/rawSxOJKoWFyCFKSjKG987i7RsG8Zszj+Sz1Vs488/vc8OYz1i7VQsvSWJQB7dIlG3dtZdH3lvKU9NWYAaX9O/IFYM7886CDYyatIj8LYVkpqdx49AcRvTJCrtcka9oNJRICFZv2sUf3lzE+Nn5NExNYm+ps7fk6/9vaanJ3DeylwJDYoZGQ4mEoH2LhvzpvD68cnV/SpxvBAVA4d4SRk1aFFJ1ItWjsBCpYT2zmrGnuLTC5/K3qE9D4oPCQqQWZKanVfyEwYNvLuLLHUW1W5BINSksRGrBjUNzSNvnLu/6KUn0aNuUP7+7lJPuf4ffjJ+jeackZml1F5FaUNaJXdFoqKUbdvD4+8sYM3MNz3+0itN7teWKgZ3p1a5ZyFWLfE2joURixPptu/nntBU8N30l24uKObFzS64Y1JkBXTMws7DLkzpAQ2dF4sj23Xt5/qNVPDltOeu3FXFk26ZcMagTZ/Zqq1X7pEYpLETiUFFxCRNm5/PY1GUs3bCDrPQ0Lh3QkR8c256G9XQFWaJPYSESx0pLnXcWbuDRKV8wa+Vm0humcsEJ2Vx4QgdaNq4fdnmSQBQWIgli1opN/H3qMibPX0+D1CR+kNue/+nficNbNgy7NEkABwoLncuKxJHc7BbkZrdg6YbtPDZ1GaNnrOLZ6Ss586hMLh/YiZ5ZGkElNUNnFiJxbP223Tw5bTnPT1/F9qJi+nfJ4PJBnejfRSOopPp0GUokwW0rG0H1wXI2bC+iR2ZTLh/UmTN6HqYRVFJlCguROqKouITxn+bx96nLWFawk3bN07h0QCd+kNuetHpaJ1wOTGEhUseUljpvLVjPo1O+4JNVW2jeMJULT8zmghOyadGoXtjlSYwKZYpyM3vSzDaY2dxybS3MbLKZLQm+Nw/azcweNrOlZva5mfUtt8+FwfZLzOzCmqpXJJEkJRmn9jiMsVeexAtXnMAxHZrzp7eWcOL9b3P7hLms3rQr7BIlztTYmYWZDQR2AM+4e8+g7f+ATe5+v5ndDDR391+b2RnA1cAZwHHAQ+5+nJm1AGYBuYADHwPHuPvmA723zixEvm3J+u38feoyJszOo9ThzF5tuUwjqKScUM4s3H0qsGmf5uHA08Hjp4ER5dqf8YjpQLqZtQWGApPdfVMQEJOB02qqZpFE1rVNE35/7tFMvek7XNK/I+8s3MBZf/6A85/4iGlLvyQRL0lL9NT2MIk27r4WIPjeOmjPAlaX225N0La/9m8xs8vMbJaZzSooKIh64SKJom2zNG4940im3TyEm07LYcHa7fzk8Y84+y8f8PJn+RSXVLxQk9RtsTKmrqIB4X6A9m83uj/m7rnuntuqVauoFieSiJqlpXLl4C588OvvcP/IXuwqKuHq0Z8y5A9T+Nd/V1C4pyTsEiWG1HZYrA8uLxF83xC0rwHal9uuHZB/gHYRiZIGqcmc1+9wJl8/iEd/egwtGtXjtxPmcdID7/Dw20vYvHNP2CVKDKjtsJgIlI1ouhCYUK79gmBU1PHA1uAy1STgVDNrHoycOjVoE5EoS04yTut5GOOuPJH/XHY8vdun8+DkxZx4/zvcMXEeazZrBFVdVmNzQ5nZaGAwkGFma4DbgfuBMWZ2CbAKODfY/DUiI6GWAruAiwDcfZOZ3QXMDLb7nbvv22kuIlFkZhzXqSXHdWrJonWROaienb6Sf01fydlHteWygZ1ZvH57hav+SeLSTXkiUqn8LYU8+cFyRs9Yxc49JSQZlJb76EhLTea+kb0UGHEulKGzIpI4MtPT+M1Z3fnw5pNp2iDlG0EBULi3hAfeWBhOcVIrFBYiUmXNGqayfXdxhc+t3bqbc/46jT+9tZjZq7dQum+iSFzTehYiUi2Z6WnkbSn8VnuTBimUljoPvb2EP721hBaN6jGgawaDc1oxsGsrreoX5xQWIlItNw7N4Zaxcyjc+/V9GGmpydw1vCcj+mSxcUcR7y/5kimLC5i6uIAJs/Mxg15ZzRjcrRWDclrTu306yUlabyOeqINbRKpt/Kd5VRoNVVrqzMnbypTFBby3aEPk8pRHbggc0DWDQd1aMSinFa2bNAjhKGRfmqJcRGLCll17eH/Jl7y3qIApiwv4ckcRAD0ymzKoWysG57Sm7+HpWrApJAoLEYk5paXO/LXbmLK4gCmLCvh41WZKSp0mDVLo3yXS1zGoW2sOa6azjtqisBCRmLe1cC/Tln7JlEUFvLd4A+u3Rc46jjisCYNyWjGoWytyO7SgXorOOmqKwkJE4oq7s3Dd9q/6Omat2ExxqdOoXjIndclgUE7kklVWelrYpSYUhYWIxLXtu/fy4RcbI30dizaQv3U3AF1bN/6qr+PYjs2pn6J1xg+FwkJEEoa7s3TDjuCso4AZyzexp6SUtNRkTuzcksHBWUf7Fg3DLjXuKCxEJGHtLCpm+rLIWcd7izewelPkhsFOGY2+6us4vlNLGqTqrKMyCgsRqRPcneVf7gyCo4Dpyzayp7iU+ilJnNC55VeXrDpmNAKqfr9IXaGwEJE6qXBPCdOXb2RKcF/H8i93AtChZUPaN09jxjwzviUAAAvpSURBVPLN7Cm3jGxdnz33QGGh6T5EJGGl1UvmOzmt+U5OawBWbtz5VV/HOws3fGv7wr0ljJq0qM6GxYFowLKI1BkdWjbighOyefJnx7K/manythTyxtx1FBVrDfLydGYhInXS/mbPTTK44tmPadIghTN6tmV470yO69Syzk98qLAQkTppf7Pn3jOiBy0a12fi7Hxe+Tyf/8xaTZum9Tn7qExG9MmiR2ZTzOpecCgsRKROKuuX2N9oqME5rSncU8JbC9YzYXY+T/93BY9/sJxOrRoxoncWw47OJDsYVVUXaDSUiEgVbN65h9fnrmPC7Dw+Wr4JgKPbpzOidyZnHtU2IaZZ19BZEZEoyt9SyMuf5TN+dj4L1m4jyeCkLhkM753F0B5taNIgNewSD4rCQkSkhixev52Js/OZ8FkeqzcVUj8liVOObMOw3pkMzmkVV/NVKSxERGqYu/PJqi1MmJ3HK5+vZdPOPTRtkMIZvdoyrHcmx3dsSVKMj6hSWIiI1KK9JaV8sPRLJs7OZ9K8dezaU8JhTRtw9tFtGd47dkdUKSxEREKya08xby3YwMTZeby3qIDiUqdzq0YM753F8N6ZdGgZOyOqFBYiIjFg8849vDZ3LRM+zWfGisiIqt5fjajKpFWT+qHWp7AQEYkxeWUjqj7NY+G67V+NqBrRO4tTQxpRpbAQEYlhi9ZtZ8LsPCbMzidvSzCiqnsbhh+dyaBaHFGlsBARiQOREVWbGf9pPq/OiYyoapaWyhm9DmPY0Vkc17FFjY6oUliIiMSZshFVEz7N4835678aUTWsdybDe2fSvW30R1QpLERE4tiuPcVMnr+eibPzmbI4MqKqS+vGDD86k+G9szi8ZcOorPqnsBARSRCbdu7htTlrmTA7j5krNgPQoUUa+Vt3s7fk68/zg1n1T2EhIpKA1mzexcufreUPby6iuPTbn+VZ6WlMu3lIlV/vQGGhlfJEROJUu+YN+fngzpRUEBQQmfAwWhQWIiJxLjM9rVrtB0NhISIS524cmkNa6jfvxUhLTebGoTlRe49QwsLMfmlmc81snpldG7S1MLPJZrYk+N48aDcze9jMlprZ52bWN4yaRURi1Yg+Wdw3shdZ6WkYkb6K6nZuV6bWl1U1s57ApUA/YA/whpm9GrS97e73m9nNwM3Ar4HTga7B13HA34LvIiISGNEnK6rhsK8wziyOBKa7+y53LwamAOcAw4Gng22eBkYEj4cDz3jEdCDdzNrWdtEiInVZGGExFxhoZi3NrCFwBtAeaOPuawGC762D7bOA1eX2XxO0fYOZXWZms8xsVkFBQY0egIhIXVPrYeHuC4AHgMnAG8BnQPEBdqnofvZvjRNz98fcPdfdc1u1ahWVWkVEJCKUDm53f8Ld+7r7QGATsARYX3Z5Kfi+Idh8DZEzjzLtgPzarFdEpK4LazRU6+D74cBIYDQwEbgw2ORCYELweCJwQTAq6nhga9nlKhERqR2hTPdhZu8DLYG9wPXu/raZtQTGAIcDq4Bz3X2TRaZV/AtwGrALuMjdDziXh5kVACsPocQM4MtD2D9WJMpxgI4lViXKsSTKccChHUsHd6/wOn5Czg11qMxs1v7mR4kniXIcoGOJVYlyLIlyHFBzx6I7uEVEpFIKCxERqZTComKPhV1AlCTKcYCOJVYlyrEkynFADR2L+ixERKRSOrMQEZFKKSxERKRSCouAmbU3s3fNbEEwdfovw67pYJlZAzObYWafBcdyZ9g1HQozSzazT83slbBrORRmtsLM5pjZbDOL63V/zSzdzF40s4XB/5kTwq7pYJhZTvD3Ufa1rWzZhHhkZtcF/+fnmtloM2sQtddWn0VEMMVIW3f/xMyaAB8DI9x9fsilVVtwI2Mjd99hZqnAB8Avg1l7446ZXQ/kAk3d/ayw6zlYZrYCyHX3uL/5y8yeBt5398fNrB7Q0N23hF3XoTCzZCAPOM7dD+Wm3lCYWRaR/+vd3b3QzMYAr7n7U9F4fZ1ZBNx9rbt/EjzeDiyggtlt40EwnfuO4MfU4Csufysws3bAmcDjYdciEWbWFBgIPAHg7nviPSgCJwNfxGNQlJMCpJlZCtCQKM6jp7CogJllA32Aj8Kt5OAFl25mE5mQcbK7x+ux/Am4CSgNu5AocOBNM/vYzC4Lu5hD0AkoAP4ZXB583MwahV1UFJxHZJ66uOTuecDviUyXtJbIPHpvRuv1FRb7MLPGwEvAte6+Lex6Dpa7l7h7byKz9PYLViiMK2Z2FrDB3T8Ou5YoOcnd+xJZ/fEXZjYw7IIOUgrQF/ibu/cBdhJZ2TJuBZfShgEvhF3LwQqWoh4OdAQygUZm9tNovb7Copzg+v5LwHPuPjbseqIhuDzwHpGJGOPNScCw4Fr/v4EhZvZsuCUdPHfPD75vAMYRWVo4Hq0B1pQ7W32RSHjEs9OBT9x9fdiFHIJTgOXuXuDue4GxwInRenGFRSDoFH4CWODuD4Zdz6Ews1Zmlh48TiPyj2hhuFVVn7vf4u7t3D2byCWCd9w9ar8p1SYzaxQMnCC4ZHMqkVUj4467rwNWm1lO0HQyEHcDQfbxI+L4ElRgFXC8mTUMPs9OJtL3GhUp0XqhBHAScD4wJ7jWD3Cru78WYk0Hqy3wdDC6IwkY4+5xPew0AbQBxkX+D5MCPO/ub4Rb0iG5GnguuHyzDLgo5HoOWrC883eBy8Ou5VC4+0dm9iLwCZHVRz8lilN/aOisiIhUSpehRESkUgoLERGplMJCREQqpbAQEZFKKSxERKRSCguJaWbmZvaHcj//yszuiNJrP2Vm34/Ga1XyPucGM7O+W5N1mVm2mf24+hVW+31q5c9NYovCQmJdETDSzDLCLqS84B6WqroEuNLdv1NT9QSygWqFRTWPQ+owhYXEumIiNxZdt+8T+/6Ga2Y7gu+DzWyKmY0xs8Vmdr+Z/SRY42OOmXUu9zKnmNn7wXZnBfsnm9koM5tpZp+b2eXlXvddM3semFNBPT8KXn+umT0QtP0v0B941MxGVbDPTcE+n5nZ/RU8v6IsKM0s18zeCx4PKrcGw6fB3eH3AwOCtuuqehzB3eWvBjXMNbMfVuUvJnitu4K/B32WJDjdwS3x4BHgczP7v2rsczRwJLCJyB3Gj7t7P4ssanU1ULbATTYwCOgMvGtmXYALiMzYeayZ1QemmVnZ7J39gJ7uvrz8m5lZJvAAcAywmcjssiPc/XdmNgT4lbvP2mef04ERRNZP2GVmLapxfL8CfuHu04LJL3cTmczvV2VrfgQz21Z6HGb2PSDf3c8M9mtWlQKCv49mwEWuu3sTnn4bkJgXzP77DHBNNXabGaxRUgR8AZR9SM4hEhBlxrh7qbsvIRIqRxCZt+mCYNqXj4CWQNdg+xn7BkXgWOC9YBK3YuA5Ims+HMgpwD/dfVdwnJuqcXzTgAfN7BogPXjPfVX1OOYQOcN6wMwGuPvWKrz/b4P3vVxBUTcoLCRe/InItf/y6yYUE/wbDiZOq1fuuaJyj0vL/VzKN8+o9/2gc8CAq929d/DVsdy6ADv3U59V9UD22aeyD9qvjhH4aolMd78f+B8gDZhuZkfs5/UrPQ53X0zkjGgOcF9w6awyM4Fjqnk2JHFMYSFxIfitewyRwCizgsiHHETm8U89iJc+18ySgn6MTsAiYBLwc4tMWY+ZdbPKF/f5CBhkZhlBp/GPgCmV7PMmcHEwkR37+eBdwdfH+L2yRjPr7O5z3P0BYBaRM6LtQJNy+1bpOIJLaLvc/Vkii+f0DdrvM7Nz9lP7G0T6SF4N+kskwanPQuLJH4Cryv38D2CCmc0A3mb/v/UfyCIiH+ptgCvcfbeZPU7kUtUnwRlLAZG+hf1y97VmdgvwLpHf6F9z9wmV7POGmfUGZpnZHuA14NZ9NrsTeMLMbuWbKzdea2bfAUqITA/+OpGzpmIz+wx4CnioisfRCxhlZqXAXuDn5donHqD+F4KgmGhmZ7h74YGOV+KbZp0VkQqZ2SR3Hxp2HRIbFBYiIlIp9VmIiEilFBYiIlIphYWIiFRKYSEiIpVSWIiISKUUFiIiUqn/ByuthGQjIl5EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "######################################## scree plot to determine number of clusters #########################\n",
    "\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "clustNos = [2,3,4,5,6,7,8]\n",
    "Inertia = []\n",
    "\n",
    "for i in clustNos :\n",
    "    model = MiniBatchKMeans(n_clusters=i,random_state=2019)\n",
    "    model.fit(x_train_scaled)\n",
    "    Inertia.append(model.inertia_)\n",
    "    \n",
    "# Import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(clustNos, Inertia, '-o')\n",
    "plt.title(\"Scree Plot\")\n",
    "plt.xlabel('Number of clusters, k')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(clustNos)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training K means clusering for K=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337, 59)\n",
      "(425, 59)\n",
      "(480, 59)\n"
     ]
    }
   ],
   "source": [
    "model_km= MiniBatchKMeans(n_clusters=3,random_state=2019,n_init=20)\n",
    "model_km.fit(x_train_scaled)\n",
    "ClusterID = model_km.predict(x_train_scaled)\n",
    "ClusterID = pd.DataFrame(ClusterID,index=x_train.index,columns=[\"Cluster\"])\n",
    "Clust_x_train = pd.concat([ClusterID,y_train,x_train],axis=\"columns\")\n",
    "\n",
    "Clust0 = Clust_x_train[Clust_x_train['Cluster']==0]\n",
    "Clust1 = Clust_x_train[Clust_x_train['Cluster']==1]\n",
    "Clust2 = Clust_x_train[Clust_x_train['Cluster']==2]\n",
    "\n",
    "\n",
    "print(Clust0.shape)\n",
    "print(Clust1.shape)\n",
    "print(Clust2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   applying Supervised Learning models on each clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################  train cluster 0 ##################################\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "Clust0[\"emotions\"].value_counts()\n",
    "X0 = Clust0.iloc[:,2:]\n",
    "y0 = Clust0[\"emotions\"]\n",
    "\n",
    "X0_train, X0_test, y0_train, y0_test = train_test_split(X0, y0, test_size = 0.2,                                                  random_state=2019,\n",
    "                                                   stratify=y0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Cluster 0 with GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### scaling the input data ####################\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X0_train_scaled=scaler.fit_transform(X0_train)\n",
    "\n",
    "X0_train_scaled = pd.DataFrame(X0_train_scaled,\n",
    "                          columns=X0_train.columns,\n",
    "                          index=X0_train.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " ############## set tuning parameters #####################\n",
    "    \n",
    "lr_range = np.linspace(0.001,1,30)\n",
    "n_est_range = np.arange(10,200,20)\n",
    "depth_range = np.arange(5,50,5)\n",
    "minleaf_range = np.arange(10,50,10)\n",
    "\n",
    "parameters = dict(learning_rate=lr_range,              \n",
    "                  max_depth=depth_range,\n",
    "                  min_samples_leaf=minleaf_range)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=42)\n",
    "clf = GradientBoostingClassifier(random_state=2019)\n",
    "gb0 = RandomizedSearchCV(clf, param_distributions=parameters,cv=kfold,scoring='neg_log_loss',verbose=3,n_jobs=-1)\n",
    "gb0.fit(X0_train,y0_train)\n",
    "X0_test.reset_index(drop=True)\n",
    "y0_pred0_proba_gb=gb0.predict_proba(X0_test)\n",
    "\n",
    "    \n",
    "print(\"ROC_auc_score for Gradient Boost:\\n\",roc_auc_score(y0_test, y0_pred0_proba_gb,multi_class='ovr'))\n",
    "\n",
    "print(gb0.best_params_)\n",
    "\n",
    "print(\"loss for Gradient Boost Model\",gb0.best_score_)\n",
    "\n",
    "\n",
    "#print(y0_test.value_counts())\n",
    "#print(y0_pred0_proba_gb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Cluster 0 with Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 429 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 170, 'min_samples_split': 15, 'min_samples_leaf': 10, 'max_features': 51, 'max_depth': 10}\n",
      "-1.5618877510103588\n",
      "ROC_AUC rf 0.8043857854147589\n"
     ]
    }
   ],
   "source": [
    "################### Random Forest ###############\n",
    "\n",
    "n_est_range = np.arange(10,200,20)\n",
    "depth_range = np.arange(5,50,5)\n",
    "max_feat_range = np.arange(20,52)\n",
    "minleaf_range = np.arange(10,50,10)\n",
    "minsplit_range = np.arange(5,50,5)\n",
    "\n",
    "parameters = dict(n_estimators=n_est_range,\n",
    "                  max_depth=depth_range,\n",
    "                  min_samples_split=minsplit_range,\n",
    "                  min_samples_leaf=minleaf_range,\n",
    "                  max_features=max_feat_range)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(random_state=2019)\n",
    "\n",
    "rf0 = RandomizedSearchCV(model_rf, param_distributions =parameters,\n",
    "                  cv=kfold,scoring='neg_log_loss',verbose=3,n_iter=100,n_jobs=-1)\n",
    "\n",
    "rf0.fit(X0_train,y0_train)\n",
    "\n",
    "\n",
    "print(rf0.best_params_)\n",
    "\n",
    "print(rf0.best_score_)\n",
    "\n",
    "y_pred0_proba_RF=rf0.predict_proba(X0_test)\n",
    "\n",
    "print(\"ROC_AUC rf\",roc_auc_score(y0_test, y_pred0_proba_RF, multi_class='ovr'))   \n",
    "\n",
    "\n",
    "#ROC_AUC rf 0.8043857854147589"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Cluster 0 with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=120, max_depth=8, learning_rate=0.001 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=120, max_depth=8, learning_rate=0.001, score=-2.029, total=   2.0s\n",
      "[CV] n_estimators=120, max_depth=8, learning_rate=0.001 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=120, max_depth=8, learning_rate=0.001, score=-2.034, total=   2.0s\n",
      "[CV] n_estimators=120, max_depth=8, learning_rate=0.001 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=120, max_depth=8, learning_rate=0.001, score=-1.984, total=   1.9s\n",
      "[CV] n_estimators=120, max_depth=8, learning_rate=0.001 ..............\n",
      "[CV]  n_estimators=120, max_depth=8, learning_rate=0.001, score=-2.029, total=   1.9s\n",
      "[CV] n_estimators=120, max_depth=8, learning_rate=0.001 ..............\n",
      "[CV]  n_estimators=120, max_depth=8, learning_rate=0.001, score=-1.988, total=   1.9s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.1 ...............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.1, score=-1.557, total=   1.4s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.1 ...............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.1, score=-1.622, total=   1.4s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.1 ...............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.1, score=-1.296, total=   1.5s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.1 ...............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.1, score=-1.702, total=   1.5s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.1 ...............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.1, score=-1.302, total=   1.5s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.2 ...............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.2, score=-1.563, total=   1.1s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.2 ...............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.2, score=-1.665, total=   1.0s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.2 ...............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.2, score=-1.328, total=   1.0s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.2 ...............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.2, score=-1.778, total=   1.0s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.2 ...............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.2, score=-1.339, total=   1.1s\n",
      "[CV] n_estimators=10, max_depth=10, learning_rate=0.01 ...............\n",
      "[CV]  n_estimators=10, max_depth=10, learning_rate=0.01, score=-2.035, total=   0.2s\n",
      "[CV] n_estimators=10, max_depth=10, learning_rate=0.01 ...............\n",
      "[CV]  n_estimators=10, max_depth=10, learning_rate=0.01, score=-2.040, total=   0.2s\n",
      "[CV] n_estimators=10, max_depth=10, learning_rate=0.01 ...............\n",
      "[CV]  n_estimators=10, max_depth=10, learning_rate=0.01, score=-1.999, total=   0.2s\n",
      "[CV] n_estimators=10, max_depth=10, learning_rate=0.01 ...............\n",
      "[CV]  n_estimators=10, max_depth=10, learning_rate=0.01, score=-2.035, total=   0.2s\n",
      "[CV] n_estimators=10, max_depth=10, learning_rate=0.01 ...............\n",
      "[CV]  n_estimators=10, max_depth=10, learning_rate=0.01, score=-2.002, total=   0.2s\n",
      "[CV] n_estimators=20, max_depth=4, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=4, learning_rate=0.3, score=-1.519, total=   0.2s\n",
      "[CV] n_estimators=20, max_depth=4, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=4, learning_rate=0.3, score=-1.619, total=   0.2s\n",
      "[CV] n_estimators=20, max_depth=4, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=4, learning_rate=0.3, score=-1.364, total=   0.2s\n",
      "[CV] n_estimators=20, max_depth=4, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=4, learning_rate=0.3, score=-1.664, total=   0.2s\n",
      "[CV] n_estimators=20, max_depth=4, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=4, learning_rate=0.3, score=-1.393, total=   0.2s\n",
      "[CV] n_estimators=20, max_depth=8, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=8, learning_rate=0.3, score=-1.606, total=   0.3s\n",
      "[CV] n_estimators=20, max_depth=8, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=8, learning_rate=0.3, score=-1.612, total=   0.3s\n",
      "[CV] n_estimators=20, max_depth=8, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=8, learning_rate=0.3, score=-1.374, total=   0.3s\n",
      "[CV] n_estimators=20, max_depth=8, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=8, learning_rate=0.3, score=-1.650, total=   0.3s\n",
      "[CV] n_estimators=20, max_depth=8, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=8, learning_rate=0.3, score=-1.416, total=   0.3s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.25 ................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.25, score=-1.541, total=   0.6s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.25 ................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.25, score=-1.603, total=   0.5s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.25 ................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.25, score=-1.351, total=   0.5s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.25 ................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.25, score=-1.715, total=   0.5s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.25 ................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.25, score=-1.403, total=   0.5s\n",
      "[CV] n_estimators=120, max_depth=10, learning_rate=0.1 ...............\n",
      "[CV]  n_estimators=120, max_depth=10, learning_rate=0.1, score=-1.547, total=   1.3s\n",
      "[CV] n_estimators=120, max_depth=10, learning_rate=0.1 ...............\n",
      "[CV]  n_estimators=120, max_depth=10, learning_rate=0.1, score=-1.613, total=   1.4s\n",
      "[CV] n_estimators=120, max_depth=10, learning_rate=0.1 ...............\n",
      "[CV]  n_estimators=120, max_depth=10, learning_rate=0.1, score=-1.304, total=   1.3s\n",
      "[CV] n_estimators=120, max_depth=10, learning_rate=0.1 ...............\n",
      "[CV]  n_estimators=120, max_depth=10, learning_rate=0.1, score=-1.671, total=   1.3s\n",
      "[CV] n_estimators=120, max_depth=10, learning_rate=0.1 ...............\n",
      "[CV]  n_estimators=120, max_depth=10, learning_rate=0.1, score=-1.311, total=   1.3s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.01 ................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.01, score=-1.893, total=   0.8s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.01 ................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.01, score=-1.934, total=   0.8s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.01 ................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.01, score=-1.819, total=   0.7s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.01 ................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.01, score=-1.890, total=   0.7s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.01 ................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.01, score=-1.809, total=   0.8s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.001 ..............\n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.001, score=-2.033, total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.001 ..............\n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.001, score=-2.050, total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.001 ..............\n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.001, score=-2.017, total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.001 ..............\n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.001, score=-2.038, total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.001 ..............\n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.001, score=-2.024, total=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   42.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4891564747031614\n",
      "{'n_estimators': 120, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "ROC_AUC rf 0.8448378631904228\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "lr_range = [0.001, 0.01, 0.1, 0.2,0.25, 0.3]\n",
    "n_est_range = [10,20,30,50,100,120,150]\n",
    "md_range = [2,4,6,8,10]\n",
    "\n",
    "\n",
    "\n",
    "parameters = dict(learning_rate=lr_range,n_estimators=n_est_range, max_depth=md_range)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "clf = XGBClassifier(random_state=2019)\n",
    "xgb0 = RandomizedSearchCV(clf, param_distributions=parameters,cv=5,scoring='neg_log_loss',verbose=3)\n",
    "xgb0.fit(X0_train,y0_train)\n",
    "print(xgb0.best_score_)\n",
    "print(xgb0.best_params_)\n",
    "y_pred0_proba=xgb0.predict_proba(X0_test)\n",
    "print(\"ROC_AUC rf\",roc_auc_score(y0_test, y_pred0_proba, multi_class='ovr'))   \n",
    "\n",
    "#ROC_AUC rf 0.8448378631904228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC rf 0.49645255390834864\n"
     ]
    }
   ],
   "source": [
    "########################################### MultinomialNB #####################################################\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "multinomial = MultinomialNB()\n",
    "\n",
    "mul=multinomial.fit(X0_train_scaled, y0_train) # Model Building\n",
    "y_pred0_proba_mul=mul.predict_proba(X0_test)\n",
    "print(\"ROC_AUC rf\",roc_auc_score(y0_test, y_pred0_proba_mul, multi_class='ovr'))   \n",
    "#ROC_AUC rf 0.49645255390834864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############################################  MLP ##########################################\n",
    "\n",
    "\n",
    "lr_range = np.linspace(0.01,0.8,10)\n",
    "hl_range = [(400,200,150,200,250,100,300)]\n",
    "act_range = ['logistic','tanh','sigmoid']\n",
    "parameters = dict(learning_rate_init=lr_range,hidden_layer_sizes = hl_range,\n",
    "                  activation = act_range)\n",
    "\n",
    "mlp=MLPClassifier()\n",
    "model_mlp=RandomizedSearchCV(clf, param_distributions=parameters,cv=5,scoring='neg_log_loss',verbose=3)\n",
    "model_mlp.fit(X0_train_scaled, y0_train)\n",
    "\n",
    "y_pred0_proba_mlp=mul.predict_proba(X0_test)\n",
    "\n",
    "print(model_mlp.best_score_)\n",
    "print(model_mlp.best_params_)\n",
    "\n",
    "print(\"ROC_AUC rf\",roc_auc_score(y0_test, y_pred0_proba_mlp, multi_class='ovr'))  \n",
    "\n",
    "#ROC_AUC rf 0.49645255390834864"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Cluster 1 with GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### train cluster 1 ##################################\n",
    "\n",
    "\n",
    "\n",
    "Clust1[\"emotions\"].value_counts()\n",
    "X1 = Clust1.iloc[:,2:]\n",
    "y1 = Clust1[\"emotions\"]\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.2,                                                  random_state=2019,\n",
    "                                                   stratify=y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dai\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  50 | elapsed:    4.7s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_auc_score for Gradient Boost:\n",
      " 0.8100625720044856\n",
      "{'n_estimators': 30, 'min_samples_leaf': 30, 'max_depth': 40, 'learning_rate': 0.24213793103448275}\n",
      "loss for Gradient Boost Model -1.57155940039346\n",
      "1    17\n",
      "2    14\n",
      "6    13\n",
      "7    10\n",
      "4     9\n",
      "5     8\n",
      "3     7\n",
      "0     7\n",
      "Name: emotions, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "############################### scaling the input data ####################\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X1_train_scaled=scaler.fit_transform(X1_train)\n",
    "\n",
    "X1_train_scaled = pd.DataFrame(X1_train_scaled,\n",
    "                          columns=X1_train.columns,\n",
    "                          index=X1_train.index)\n",
    "\n",
    "\n",
    "lr_range = np.linspace(0.001,1,30)\n",
    "n_est_range = np.arange(10,50,20)\n",
    "depth_range = np.arange(5,50,5)\n",
    "minleaf_range = np.arange(10,50,10)\n",
    "\n",
    "parameters = dict(learning_rate=lr_range,              \n",
    "                  max_depth=depth_range,\n",
    "                  min_samples_leaf=minleaf_range,n_estimators=n_est_range )\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=42)\n",
    "GB1 = GradientBoostingClassifier(random_state=2019)\n",
    "model_GB1 = RandomizedSearchCV(GB1, param_distributions=parameters,cv=kfold,scoring='neg_log_loss',verbose=3,n_jobs=-1)\n",
    "model_GB1.fit(X1_train,y1_train)\n",
    "X1_test.reset_index(drop=True)\n",
    "y1_pred1_proba_GB=model_GB1.predict_proba(X1_test)\n",
    "#y0_pred0_proba1=pd.DataFrame(y0_pred0_proba1)\n",
    "#y0_pred0_proba_em=y0_pred0_proba1.idxmax(axis=1)\n",
    "#y0_pred0_proba=y0_pred0_proba1.max(axis=1)\n",
    "#y0_pred0_proba3=pd.DataFrame(y0_pred0_proba)\n",
    "#y0_test1=pd.DataFrame(y0_test)\n",
    "#def fun():\n",
    "#    global y0_pred0_proba1\n",
    "#    print(\"test\")\n",
    "#    for i,row in y0_pred0_proba1.iterrows():    \n",
    "#        c=(max(row))\n",
    "#        print (c)\n",
    "    \n",
    "print(\"ROC_auc_score for Gradient Boost:\\n\",roc_auc_score(y1_test, y1_pred1_proba_GB,multi_class='ovr'))\n",
    "\n",
    "print(model_GB1.best_params_)\n",
    "\n",
    "print(\"loss for Gradient Boost Model\",model_GB1.best_score_)\n",
    "\n",
    "print(y1_test.value_counts())\n",
    "\n",
    "\n",
    "#ROC_auc_score for Gradient Boost: 0.8100625720044856\n",
    "#{'n_estimators': 30, 'min_samples_leaf': 30, 'max_depth': 40, 'learning_rate': 0.24213793103448275}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Cluster 1 with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   13.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 190, 'min_samples_split': 15, 'min_samples_leaf': 10, 'max_features': 50, 'max_depth': 30}\n",
      "-1.643701330257354\n",
      "ROC_AUC rf 0.7916737542025991\n"
     ]
    }
   ],
   "source": [
    "################### Random Forest ###############\n",
    "\n",
    "\n",
    "n_est_range = np.arange(10,200,20)\n",
    "depth_range = np.arange(5,50,5)\n",
    "max_feat_range = np.arange(20,57)\n",
    "minleaf_range = np.arange(10,50,10)\n",
    "minsplit_range = np.arange(5,50,5)\n",
    "\n",
    "parameters = dict(n_estimators=n_est_range,\n",
    "                  max_depth=depth_range,\n",
    "                  min_samples_split=minsplit_range,\n",
    "                  min_samples_leaf=minleaf_range,\n",
    "                  max_features=max_feat_range)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf1 = RandomForestClassifier(random_state=2019)\n",
    "\n",
    "model_rf1 = RandomizedSearchCV(rf1, param_distributions =parameters,\n",
    "                  cv=kfold,scoring='neg_log_loss',verbose=3,n_iter=100,n_jobs=-1)\n",
    "\n",
    "model_rf1.fit(X1_train,y1_train)\n",
    "\n",
    "\n",
    "print(model_rf1.best_params_)\n",
    "\n",
    "print(model_rf1.best_score_)\n",
    "\n",
    "y_pred1_proba_RF=model_rf1.predict_proba(X1_test)\n",
    "\n",
    "print(\"ROC_AUC rf\",roc_auc_score(y1_test, y_pred1_proba_RF, multi_class='ovr'))   \n",
    "\n",
    "#{'n_estimators': 190, 'min_samples_split': 15, 'min_samples_leaf': 10, 'max_features': 50, 'max_depth': 30}\n",
    "#-1.643701330257354\n",
    "#ROC_AUC rf 0.7916737542025991\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Cluster 1 with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.1 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.1, score=-1.476, total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.1 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.1, score=-1.567, total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.1 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.1, score=-1.559, total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.1 ................\n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.1, score=-1.688, total=   0.8s\n",
      "[CV] n_estimators=100, max_depth=2, learning_rate=0.1 ................\n",
      "[CV]  n_estimators=100, max_depth=2, learning_rate=0.1, score=-1.524, total=   0.9s\n",
      "[CV] n_estimators=20, max_depth=2, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=2, learning_rate=0.3, score=-1.537, total=   0.2s\n",
      "[CV] n_estimators=20, max_depth=2, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=2, learning_rate=0.3, score=-1.627, total=   0.2s\n",
      "[CV] n_estimators=20, max_depth=2, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=2, learning_rate=0.3, score=-1.581, total=   0.2s\n",
      "[CV] n_estimators=20, max_depth=2, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=2, learning_rate=0.3, score=-1.755, total=   0.2s\n",
      "[CV] n_estimators=20, max_depth=2, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=2, learning_rate=0.3, score=-1.533, total=   0.2s\n",
      "[CV] n_estimators=30, max_depth=8, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=30, max_depth=8, learning_rate=0.1, score=-1.476, total=   0.7s\n",
      "[CV] n_estimators=30, max_depth=8, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=30, max_depth=8, learning_rate=0.1, score=-1.594, total=   0.7s\n",
      "[CV] n_estimators=30, max_depth=8, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=30, max_depth=8, learning_rate=0.1, score=-1.603, total=   0.7s\n",
      "[CV] n_estimators=30, max_depth=8, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=30, max_depth=8, learning_rate=0.1, score=-1.630, total=   0.7s\n",
      "[CV] n_estimators=30, max_depth=8, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=30, max_depth=8, learning_rate=0.1, score=-1.561, total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=4, learning_rate=0.01 ...............\n",
      "[CV]  n_estimators=100, max_depth=4, learning_rate=0.01, score=-1.698, total=   1.7s\n",
      "[CV] n_estimators=100, max_depth=4, learning_rate=0.01 ...............\n",
      "[CV]  n_estimators=100, max_depth=4, learning_rate=0.01, score=-1.783, total=   1.6s\n",
      "[CV] n_estimators=100, max_depth=4, learning_rate=0.01 ...............\n",
      "[CV]  n_estimators=100, max_depth=4, learning_rate=0.01, score=-1.754, total=   1.6s\n",
      "[CV] n_estimators=100, max_depth=4, learning_rate=0.01 ...............\n",
      "[CV]  n_estimators=100, max_depth=4, learning_rate=0.01, score=-1.788, total=   1.5s\n",
      "[CV] n_estimators=100, max_depth=4, learning_rate=0.01 ...............\n",
      "[CV]  n_estimators=100, max_depth=4, learning_rate=0.01, score=-1.766, total=   1.6s\n",
      "[CV] n_estimators=10, max_depth=8, learning_rate=0.2 .................\n",
      "[CV]  n_estimators=10, max_depth=8, learning_rate=0.2, score=-1.489, total=   0.2s\n",
      "[CV] n_estimators=10, max_depth=8, learning_rate=0.2 .................\n",
      "[CV]  n_estimators=10, max_depth=8, learning_rate=0.2, score=-1.652, total=   0.3s\n",
      "[CV] n_estimators=10, max_depth=8, learning_rate=0.2 .................\n",
      "[CV]  n_estimators=10, max_depth=8, learning_rate=0.2, score=-1.641, total=   0.2s\n",
      "[CV] n_estimators=10, max_depth=8, learning_rate=0.2 .................\n",
      "[CV]  n_estimators=10, max_depth=8, learning_rate=0.2, score=-1.689, total=   0.2s\n",
      "[CV] n_estimators=10, max_depth=8, learning_rate=0.2 .................\n",
      "[CV]  n_estimators=10, max_depth=8, learning_rate=0.2, score=-1.623, total=   0.2s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.01 ..............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.01, score=-1.578, total=   3.4s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.01 ..............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.01, score=-1.683, total=   3.4s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.01 ..............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.01, score=-1.706, total=   3.4s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.01 ..............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.01, score=-1.690, total=   3.4s\n",
      "[CV] n_estimators=150, max_depth=10, learning_rate=0.01 ..............\n",
      "[CV]  n_estimators=150, max_depth=10, learning_rate=0.01, score=-1.692, total=   3.4s\n",
      "[CV] n_estimators=50, max_depth=2, learning_rate=0.25 ................\n",
      "[CV]  n_estimators=50, max_depth=2, learning_rate=0.25, score=-1.496, total=   0.4s\n",
      "[CV] n_estimators=50, max_depth=2, learning_rate=0.25 ................\n",
      "[CV]  n_estimators=50, max_depth=2, learning_rate=0.25, score=-1.529, total=   0.5s\n",
      "[CV] n_estimators=50, max_depth=2, learning_rate=0.25 ................\n",
      "[CV]  n_estimators=50, max_depth=2, learning_rate=0.25, score=-1.555, total=   0.4s\n",
      "[CV] n_estimators=50, max_depth=2, learning_rate=0.25 ................\n",
      "[CV]  n_estimators=50, max_depth=2, learning_rate=0.25, score=-1.672, total=   0.4s\n",
      "[CV] n_estimators=50, max_depth=2, learning_rate=0.25 ................\n",
      "[CV]  n_estimators=50, max_depth=2, learning_rate=0.25, score=-1.523, total=   0.4s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.1, score=-1.401, total=   1.0s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.1, score=-1.546, total=   1.0s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.1, score=-1.546, total=   1.0s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.1, score=-1.562, total=   0.9s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.1, score=-1.478, total=   1.0s\n",
      "[CV] n_estimators=10, max_depth=4, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=10, max_depth=4, learning_rate=0.1, score=-1.693, total=   0.2s\n",
      "[CV] n_estimators=10, max_depth=4, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=10, max_depth=4, learning_rate=0.1, score=-1.785, total=   0.2s\n",
      "[CV] n_estimators=10, max_depth=4, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=10, max_depth=4, learning_rate=0.1, score=-1.745, total=   0.2s\n",
      "[CV] n_estimators=10, max_depth=4, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=10, max_depth=4, learning_rate=0.1, score=-1.784, total=   0.2s\n",
      "[CV] n_estimators=10, max_depth=4, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=10, max_depth=4, learning_rate=0.1, score=-1.759, total=   0.2s\n",
      "[CV] n_estimators=20, max_depth=4, learning_rate=0.001 ...............\n",
      "[CV]  n_estimators=20, max_depth=4, learning_rate=0.001, score=-2.066, total=   0.3s\n",
      "[CV] n_estimators=20, max_depth=4, learning_rate=0.001 ...............\n",
      "[CV]  n_estimators=20, max_depth=4, learning_rate=0.001, score=-2.068, total=   0.3s\n",
      "[CV] n_estimators=20, max_depth=4, learning_rate=0.001 ...............\n",
      "[CV]  n_estimators=20, max_depth=4, learning_rate=0.001, score=-2.069, total=   0.3s\n",
      "[CV] n_estimators=20, max_depth=4, learning_rate=0.001 ...............\n",
      "[CV]  n_estimators=20, max_depth=4, learning_rate=0.001, score=-2.067, total=   0.3s\n",
      "[CV] n_estimators=20, max_depth=4, learning_rate=0.001 ...............\n",
      "[CV]  n_estimators=20, max_depth=4, learning_rate=0.001, score=-2.068, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   44.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.506646456405082\n",
      "{'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "ROC_AUC  0.8238605870323328\n"
     ]
    }
   ],
   "source": [
    "###################################   XGBoost   ##########################################\n",
    "\n",
    "lr_range = [0.001, 0.01, 0.1, 0.2,0.25, 0.3]\n",
    "n_est_range = [10,20,30,50,100,120,150]\n",
    "md_range = [2,4,6,8,10]\n",
    "\n",
    "parameters = dict(learning_rate=lr_range,n_estimators=n_est_range, max_depth=md_range)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "XGB1 = XGBClassifier(random_state=2019)\n",
    "model_XGB1 = RandomizedSearchCV(XGB1, param_distributions=parameters,cv=5,scoring='neg_log_loss',verbose=3)\n",
    "model_XGB1.fit(X1_train,y1_train)\n",
    "print(model_XGB1.best_score_)\n",
    "print(model_XGB1.best_params_)\n",
    "y_pred1_proba_XGB=model_XGB1.predict_proba(X1_test)\n",
    "print(\"ROC_AUC \",roc_auc_score(y1_test, y_pred1_proba_XGB, multi_class='ovr'))   \n",
    "\n",
    "#-1.488675482467036\n",
    "#{'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.1}\n",
    "#ROC_AUC  0.8248853363080373"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Cluster 2 with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#################################### train cluster 2 ##################################\n",
    "\n",
    "\n",
    "\n",
    "Clust1[\"emotions\"].value_counts()\n",
    "X2 = Clust2.iloc[:,2:]\n",
    "y2 = Clust2[\"emotions\"]\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 0.2,                                                  random_state=2019,\n",
    "                                                   stratify=y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dai\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  50 | elapsed:    3.7s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_auc_score for Gradient Boost:\n",
      " 0.8586810276321564\n",
      "{'n_estimators': 30, 'min_samples_leaf': 20, 'max_depth': 40, 'learning_rate': 0.06989655172413793}\n",
      "loss for Gradient Boost Model -1.3405080848187516\n",
      "0    19\n",
      "3    18\n",
      "7    14\n",
      "4    14\n",
      "6    11\n",
      "2    10\n",
      "1     7\n",
      "5     3\n",
      "Name: emotions, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "############################### scaling the input data ####################\n",
    "\n",
    "X2_train_scaled=scaler.fit_transform(X2_train)\n",
    "\n",
    "X2_train_scaled = pd.DataFrame(X2_train_scaled,\n",
    "                          columns=X2_train.columns,\n",
    "                          index=X2_train.index)\n",
    "\n",
    "\n",
    "lr_range = np.linspace(0.001,1,30)\n",
    "n_est_range = np.arange(10,50,20)\n",
    "depth_range = np.arange(5,50,5)\n",
    "minleaf_range = np.arange(10,50,10)\n",
    "\n",
    "parameters = dict(learning_rate=lr_range,              \n",
    "                  max_depth=depth_range,\n",
    "                  min_samples_leaf=minleaf_range,n_estimators=n_est_range )\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=42)\n",
    "GB2 = GradientBoostingClassifier(random_state=2019)\n",
    "model_GB2 = RandomizedSearchCV(GB2, param_distributions=parameters,cv=kfold,scoring='neg_log_loss',verbose=3,n_jobs=-1)\n",
    "model_GB2.fit(X2_train,y2_train)\n",
    "X2_test.reset_index(drop=True)\n",
    "y_pred2_proba_GB=model_GB2.predict_proba(X2_test)\n",
    "\n",
    "print(\"ROC_auc_score for Gradient Boost:\\n\",roc_auc_score(y2_test, y_pred2_proba_GB,multi_class='ovr'))\n",
    "\n",
    "print(model_GB2.best_params_)\n",
    "\n",
    "print(\"loss for Gradient Boost Model\",model_GB2.best_score_)\n",
    "\n",
    "print(y2_test.value_counts())\n",
    "\n",
    "#ROC_auc_score for Gradient Boost: 0.8586810276321564\n",
    "#{'n_estimators': 30, 'min_samples_leaf': 20, 'max_depth': 40, 'learning_rate': 0.06989655172413793}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Cluster 2 with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 318 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   16.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 190, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 48, 'max_depth': 10}\n",
      "-1.3959358272271494\n",
      "ROC_AUC rf 0.8626562341030408\n"
     ]
    }
   ],
   "source": [
    "################### Random Forest ###############\n",
    "\n",
    "\n",
    "n_est_range = np.arange(10,200,20)\n",
    "depth_range = np.arange(5,50,5)\n",
    "max_feat_range = np.arange(20,57)\n",
    "minleaf_range = np.arange(10,50,10)\n",
    "minsplit_range = np.arange(5,50,5)\n",
    "\n",
    "parameters = dict(n_estimators=n_est_range,\n",
    "                  max_depth=depth_range,\n",
    "                  min_samples_split=minsplit_range,\n",
    "                  min_samples_leaf=minleaf_range,\n",
    "                  max_features=max_feat_range)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf2 = RandomForestClassifier(random_state=2019)\n",
    "\n",
    "model_rf2 = RandomizedSearchCV(rf2, param_distributions =parameters,\n",
    "                  cv=kfold,scoring='neg_log_loss',verbose=3,n_iter=100,n_jobs=-1)\n",
    "\n",
    "model_rf2.fit(X2_train,y2_train)\n",
    "\n",
    "\n",
    "print(model_rf2.best_params_)\n",
    "\n",
    "print(model_rf2.best_score_)\n",
    "\n",
    "y_pred2_proba_RF=model_rf2.predict_proba(X2_test)\n",
    "\n",
    "print(\"ROC_AUC rf\",roc_auc_score(y2_test, y_pred2_proba_RF, multi_class='ovr'))   \n",
    "\n",
    "#{'n_estimators': 190, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 48, 'max_depth': 10}\n",
    "#-1.3959358272271494\n",
    "#ROC_AUC rf 0.8626562341030408\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Cluster 2 with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=20, max_depth=6, learning_rate=0.3 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=20, max_depth=6, learning_rate=0.3, score=-1.216, total=   0.4s\n",
      "[CV] n_estimators=20, max_depth=6, learning_rate=0.3 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=20, max_depth=6, learning_rate=0.3, score=-1.292, total=   0.4s\n",
      "[CV] n_estimators=20, max_depth=6, learning_rate=0.3 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=20, max_depth=6, learning_rate=0.3, score=-1.226, total=   0.4s\n",
      "[CV] n_estimators=20, max_depth=6, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=6, learning_rate=0.3, score=-1.638, total=   0.4s\n",
      "[CV] n_estimators=20, max_depth=6, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=20, max_depth=6, learning_rate=0.3, score=-1.275, total=   0.4s\n",
      "[CV] n_estimators=20, max_depth=10, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=20, max_depth=10, learning_rate=0.25, score=-1.217, total=   0.5s\n",
      "[CV] n_estimators=20, max_depth=10, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=20, max_depth=10, learning_rate=0.25, score=-1.336, total=   0.5s\n",
      "[CV] n_estimators=20, max_depth=10, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=20, max_depth=10, learning_rate=0.25, score=-1.246, total=   0.5s\n",
      "[CV] n_estimators=20, max_depth=10, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=20, max_depth=10, learning_rate=0.25, score=-1.573, total=   0.5s\n",
      "[CV] n_estimators=20, max_depth=10, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=20, max_depth=10, learning_rate=0.25, score=-1.289, total=   0.5s\n",
      "[CV] n_estimators=20, max_depth=8, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=20, max_depth=8, learning_rate=0.1, score=-1.348, total=   0.5s\n",
      "[CV] n_estimators=20, max_depth=8, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=20, max_depth=8, learning_rate=0.1, score=-1.428, total=   0.5s\n",
      "[CV] n_estimators=20, max_depth=8, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=20, max_depth=8, learning_rate=0.1, score=-1.456, total=   0.5s\n",
      "[CV] n_estimators=20, max_depth=8, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=20, max_depth=8, learning_rate=0.1, score=-1.649, total=   0.5s\n",
      "[CV] n_estimators=20, max_depth=8, learning_rate=0.1 .................\n",
      "[CV]  n_estimators=20, max_depth=8, learning_rate=0.1, score=-1.416, total=   0.5s\n",
      "[CV] n_estimators=50, max_depth=10, learning_rate=0.1 ................\n",
      "[CV]  n_estimators=50, max_depth=10, learning_rate=0.1, score=-1.238, total=   1.1s\n",
      "[CV] n_estimators=50, max_depth=10, learning_rate=0.1 ................\n",
      "[CV]  n_estimators=50, max_depth=10, learning_rate=0.1, score=-1.261, total=   1.0s\n",
      "[CV] n_estimators=50, max_depth=10, learning_rate=0.1 ................\n",
      "[CV]  n_estimators=50, max_depth=10, learning_rate=0.1, score=-1.267, total=   1.0s\n",
      "[CV] n_estimators=50, max_depth=10, learning_rate=0.1 ................\n",
      "[CV]  n_estimators=50, max_depth=10, learning_rate=0.1, score=-1.561, total=   1.0s\n",
      "[CV] n_estimators=50, max_depth=10, learning_rate=0.1 ................\n",
      "[CV]  n_estimators=50, max_depth=10, learning_rate=0.1, score=-1.302, total=   1.1s\n",
      "[CV] n_estimators=150, max_depth=6, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=150, max_depth=6, learning_rate=0.25, score=-1.181, total=   1.5s\n",
      "[CV] n_estimators=150, max_depth=6, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=150, max_depth=6, learning_rate=0.25, score=-1.268, total=   1.4s\n",
      "[CV] n_estimators=150, max_depth=6, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=150, max_depth=6, learning_rate=0.25, score=-1.184, total=   1.4s\n",
      "[CV] n_estimators=150, max_depth=6, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=150, max_depth=6, learning_rate=0.25, score=-1.597, total=   1.4s\n",
      "[CV] n_estimators=150, max_depth=6, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=150, max_depth=6, learning_rate=0.25, score=-1.345, total=   1.4s\n",
      "[CV] n_estimators=30, max_depth=10, learning_rate=0.3 ................\n",
      "[CV]  n_estimators=30, max_depth=10, learning_rate=0.3, score=-1.226, total=   0.5s\n",
      "[CV] n_estimators=30, max_depth=10, learning_rate=0.3 ................\n",
      "[CV]  n_estimators=30, max_depth=10, learning_rate=0.3, score=-1.255, total=   0.6s\n",
      "[CV] n_estimators=30, max_depth=10, learning_rate=0.3 ................\n",
      "[CV]  n_estimators=30, max_depth=10, learning_rate=0.3, score=-1.244, total=   0.6s\n",
      "[CV] n_estimators=30, max_depth=10, learning_rate=0.3 ................\n",
      "[CV]  n_estimators=30, max_depth=10, learning_rate=0.3, score=-1.607, total=   0.5s\n",
      "[CV] n_estimators=30, max_depth=10, learning_rate=0.3 ................\n",
      "[CV]  n_estimators=30, max_depth=10, learning_rate=0.3, score=-1.322, total=   0.5s\n",
      "[CV] n_estimators=50, max_depth=10, learning_rate=0.3 ................\n",
      "[CV]  n_estimators=50, max_depth=10, learning_rate=0.3, score=-1.235, total=   0.7s\n",
      "[CV] n_estimators=50, max_depth=10, learning_rate=0.3 ................\n",
      "[CV]  n_estimators=50, max_depth=10, learning_rate=0.3, score=-1.246, total=   0.7s\n",
      "[CV] n_estimators=50, max_depth=10, learning_rate=0.3 ................\n",
      "[CV]  n_estimators=50, max_depth=10, learning_rate=0.3, score=-1.220, total=   0.7s\n",
      "[CV] n_estimators=50, max_depth=10, learning_rate=0.3 ................\n",
      "[CV]  n_estimators=50, max_depth=10, learning_rate=0.3, score=-1.622, total=   0.7s\n",
      "[CV] n_estimators=50, max_depth=10, learning_rate=0.3 ................\n",
      "[CV]  n_estimators=50, max_depth=10, learning_rate=0.3, score=-1.352, total=   0.7s\n",
      "[CV] n_estimators=30, max_depth=4, learning_rate=0.01 ................\n",
      "[CV]  n_estimators=30, max_depth=4, learning_rate=0.01, score=-1.844, total=   0.5s\n",
      "[CV] n_estimators=30, max_depth=4, learning_rate=0.01 ................\n",
      "[CV]  n_estimators=30, max_depth=4, learning_rate=0.01, score=-1.871, total=   0.5s\n",
      "[CV] n_estimators=30, max_depth=4, learning_rate=0.01 ................\n",
      "[CV]  n_estimators=30, max_depth=4, learning_rate=0.01, score=-1.884, total=   0.5s\n",
      "[CV] n_estimators=30, max_depth=4, learning_rate=0.01 ................\n",
      "[CV]  n_estimators=30, max_depth=4, learning_rate=0.01, score=-1.960, total=   0.5s\n",
      "[CV] n_estimators=30, max_depth=4, learning_rate=0.01 ................\n",
      "[CV]  n_estimators=30, max_depth=4, learning_rate=0.01, score=-1.907, total=   0.5s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.3, score=-1.202, total=   0.7s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.3, score=-1.263, total=   0.7s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.3, score=-1.181, total=   0.7s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.3, score=-1.638, total=   0.7s\n",
      "[CV] n_estimators=50, max_depth=6, learning_rate=0.3 .................\n",
      "[CV]  n_estimators=50, max_depth=6, learning_rate=0.3, score=-1.309, total=   0.7s\n",
      "[CV] n_estimators=150, max_depth=8, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=150, max_depth=8, learning_rate=0.25, score=-1.173, total=   1.3s\n",
      "[CV] n_estimators=150, max_depth=8, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=150, max_depth=8, learning_rate=0.25, score=-1.228, total=   1.4s\n",
      "[CV] n_estimators=150, max_depth=8, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=150, max_depth=8, learning_rate=0.25, score=-1.185, total=   1.4s\n",
      "[CV] n_estimators=150, max_depth=8, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=150, max_depth=8, learning_rate=0.25, score=-1.630, total=   1.4s\n",
      "[CV] n_estimators=150, max_depth=8, learning_rate=0.25 ...............\n",
      "[CV]  n_estimators=150, max_depth=8, learning_rate=0.25, score=-1.366, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   38.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3149974532790962\n",
      "{'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.25}\n",
      "ROC_AUC  0.8902329566151146\n"
     ]
    }
   ],
   "source": [
    "###################################   XGBoost   ##########################################\n",
    "\n",
    "lr_range = [0.001, 0.01, 0.1, 0.2,0.25, 0.3]\n",
    "n_est_range = [10,20,30,50,100,120,150]\n",
    "md_range = [2,4,6,8,10]\n",
    "\n",
    "parameters = dict(learning_rate=lr_range,n_estimators=n_est_range, max_depth=md_range)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "XGB2 = XGBClassifier(random_state=2019)\n",
    "model_XGB2 = RandomizedSearchCV(XGB1, param_distributions=parameters,cv=5,scoring='neg_log_loss',verbose=3)\n",
    "model_XGB2.fit(X2_train,y2_train)\n",
    "print(model_XGB2.best_score_)\n",
    "print(model_XGB2.best_params_)\n",
    "y_pred2_proba_XGB=model_XGB2.predict_proba(X2_test)\n",
    "print(\"ROC_AUC \",roc_auc_score(y2_test, y_pred2_proba_XGB, multi_class='ovr')) \n",
    "\n",
    "\n",
    "#-1.3149974532790962\n",
    "#{'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.25}\n",
    "#ROC_AUC  0.8902329566151146"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 59)\n",
      "(61, 59)\n",
      "(20, 59)\n",
      "4    5\n",
      "0    5\n",
      "3    4\n",
      "7    2\n",
      "2    2\n",
      "1    2\n",
      "Name: emotions, dtype: int64\n",
      "ROC_AUC  0.8672289942434122\n"
     ]
    }
   ],
   "source": [
    "##################################################  TESTING ##############################################\n",
    "\n",
    "X_test_scaled=scaler.transform(x_test)\n",
    "\n",
    "ClusterID = model_km.predict(X_test_scaled)\n",
    "ClusterID = pd.DataFrame(ClusterID,index=x_test.index,columns=[\"Cluster\"])\n",
    "\n",
    "Clust_X_test = pd.concat([ClusterID,y_test,x_test],axis=\"columns\")\n",
    "\n",
    "\n",
    "\n",
    "Clust0_test = Clust_X_test[Clust_X_test['Cluster']==0]\n",
    "Clust1_test = Clust_X_test[Clust_X_test['Cluster']==1]\n",
    "Clust2_test = Clust_X_test[Clust_X_test['Cluster']==2]\n",
    "print(Clust0_test.shape)\n",
    "print(Clust1_test.shape)\n",
    "print(Clust2_test.shape)\n",
    "\n",
    "\n",
    "##### pick the best models in each clusters\n",
    "Clust0_best=gb0\n",
    "Clust1_best=model_XGB1\n",
    "Clust2_best=model_GB2\n",
    "\n",
    "\n",
    "y_testset0 = Clust0_test[\"emotions\"]\n",
    "y_testset1 = Clust1_test[\"emotions\"]\n",
    "y_testset2 = Clust2_test[\"emotions\"]\n",
    "\n",
    "print(y_testset2.value_counts()) \n",
    "\n",
    "y_pred_test_clust0 = Clust0_best.predict_proba(Clust0_test.iloc[:,2:])\n",
    "\n",
    "y_pred_test_clust1 = Clust1_best.predict_proba(Clust1_test.iloc[:,2:])\n",
    "\n",
    "y_pred_test_clust2 = Clust2_best.predict_proba(Clust2_test.iloc[:,2:])\n",
    "\n",
    "if len(y_testset1.value_counts()) < 8 :      \n",
    "    \n",
    "    y_testset0 = pd.DataFrame(y_testset0,index=y_testset0.index)\n",
    "    y_testset1 = pd.DataFrame(y_testset1,index=y_testset1.index)\n",
    "    y_testset_df=pd.concat([y_testset0,y_testset1])\n",
    "    \n",
    "    \n",
    "    y_pred_test_clust0_df= pd.DataFrame(y_pred_test_clust0,index=Clust0_test.index)\n",
    "    y_pred_test_clust1_df= pd.DataFrame(y_pred_test_clust1,index=Clust1_test.index)\n",
    "    y_pred_concat_test_df=pd.concat([y_pred_test_clust0_df,y_pred_test_clust1_df])\n",
    "    \n",
    "elif len(y_testset2.value_counts()) < 8 :\n",
    "    \n",
    "    y_testset2 = pd.DataFrame(y_testset2,index=y_testset2.index)\n",
    "    y_testset0 = pd.DataFrame(y_testset0,index=y_testset0.index)\n",
    "    y_testset_df=pd.concat([y_testset0,y_testset2])\n",
    "    \n",
    "    y_pred_test_clust0_df= pd.DataFrame(y_pred_test_clust0,index=Clust0_test.index)\n",
    "    y_pred_test_clust2_df= pd.DataFrame(y_pred_test_clust2,index=Clust2_test.index)\n",
    "    y_pred_concat_test_df=pd.concat([y_pred_test_clust0_df,y_pred_test_clust2_df])\n",
    "\n",
    "else:\n",
    "    \n",
    "    y_testset0 = pd.DataFrame(y_testset0,index=y_testset0.index)\n",
    "    y_testset1 = pd.DataFrame(y_testset1,index=y_testset1.index)\n",
    "    y_testset2 = pd.DataFrame(y_testset2,index=y_testset2.index)    \n",
    "    y_testset_df=pd.concat([y_testset0,y_testset1,y_testset2])\n",
    "    \n",
    "    y_pred_test_clust0_df= pd.DataFrame(y_pred_test_clust0,index=Clust0_test.index)\n",
    "    y_pred_test_clust1_df= pd.DataFrame(y_pred_test_clust1,index=Clust1_test.index)\n",
    "    y_pred_test_clust2_df= pd.DataFrame(y_pred_test_clust2,index=Clust2_test.index)\n",
    "    y_pred_concat_test_df=pd.concat([y_pred_test_clust0_df,y_pred_test_clust1_df,y_pred_test_clust2_df])     \n",
    "\n",
    "#print(\"ROC_AUC \",roc_auc_score(y_testset0,y_pred_test_clust0, multi_class='ovr'))  \n",
    "#ROC_AUC  0.8447395777744287\n",
    "\n",
    "\n",
    "#print(\"ROC_AUC \",roc_auc_score(y_testset1,y_pred_test_clust1, multi_class='ovr'))  \n",
    "#ROC_AUC  0.8574143005768946\n",
    "\n",
    "\n",
    "#print(\"ROC_AUC \",roc_auc_score(y_testset2,y_pred_test_clust2, multi_class='ovr'))  \n",
    "\n",
    "\n",
    "print(\"ROC_AUC \",roc_auc_score(y_testset_df,y_pred_concat_test_df, multi_class='ovr'))  \n",
    "\n",
    "#ROC_AUC  0.8672289942434122"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNSEEN DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClusterID_TEST = model_km.predict(X_TEST_scaled)\n",
    "ClusterID_TEST = pd.DataFrame(ClusterID_TEST,index=XT.index,columns=[\"Cluster\"])\n",
    "\n",
    "Clust_X_TEST = pd.concat([ClusterID_TEST,yT,XT],axis=\"columns\")\n",
    "\n",
    "\n",
    "Clust0_TEST = Clust_X_TEST[Clust_X_TEST['Cluster']==0]\n",
    "Clust1_TEST = Clust_X_TEST[Clust_X_TEST['Cluster']==1]\n",
    "Clust2_TEST = Clust_X_TEST[Clust_X_TEST['Cluster']==2]\n",
    "\n",
    "y_TESTset0 = Clust0_TEST[\"emotions\"]\n",
    "y_TESTset1 = Clust1_TEST[\"emotions\"]\n",
    "y_TESTset2 = Clust2_TEST[\"emotions\"]\n",
    "\n",
    "y_pred_TEST_clust0 = Clust0_best.predict_proba(Clust0_TEST.iloc[:,2:])\n",
    "\n",
    "y_TESTset0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# predictions on the clusters ################\n",
    "\n",
    "if len(y_TESTset1.value_counts()) < 8 :      \n",
    "    \n",
    "    y_TESTset0 = pd.DataFrame(y_TESTset0,index=y_TESTset0.index)\n",
    "    y_TESTset1 = pd.DataFrame(y_TESTset1,index=y_TESTset1.index)    \n",
    "    y_TESTset_df=pd.concat([y_TESTset0,y_TESTset1])\n",
    "    \n",
    "    y_pred_TEST_clust1 = Clust1_best.predict_proba(Clust1_TEST.iloc[:,2:])\n",
    "    y_pred_TEST_clust0_df= pd.DataFrame(y_pred_TEST_clust0,index=Clust0_TEST.index)\n",
    "    y_pred_TEST_clust1_df= pd.DataFrame(y_pred_TEST_clust1,index=Clust1_TEST.index) \n",
    "    y_pred_concat_TEST_df=pd.concat([y_pred_TEST_clust0_df,y_pred_TEST_clust1_df])\n",
    "    \n",
    "elif len(y_TESTset2.value_counts()) < 8 :    \n",
    "                                                   \n",
    "    y_TESTset2 = pd.DataFrame(y_TESTset2,index=y_TESTset2.index)\n",
    "    y_TESTset0 = pd.DataFrame(y_TESTset0,index=y_TESTset0.index)\n",
    "    y_TESTset_df=pd.concat([y_TESTset0,y_TESTset2])\n",
    "    \n",
    "    y_pred_TEST_clust2 = Clust2_best.predict_proba(Clust2_TEST.iloc[:,2:])\n",
    "    y_pred_TEST_clust0_df= pd.DataFrame(y_pred_TEST_clust0,index=Clust0_TEST.index)\n",
    "    y_pred_TEST_clust2_df= pd.DataFrame(y_pred_TEST_clust2,index=Clust2_TEST.index)\n",
    "    y_pred_concat_TEST_df=pd.concat([y_pred_TEST_clust0_df,y_pred_TEST_clust2_df])\n",
    "\n",
    "else:\n",
    "    \n",
    "    y_pred_TEST_clust1 = Clust1_best.predict_proba(Clust1_TEST.iloc[:,2:])\n",
    "    y_pred_TEST_clust2 = Clust2_best.predict_proba(Clust2_TEST.iloc[:,2:])\n",
    "    y_TESTset0 = pd.DataFrame(y_TESTset0,index=y_TESTset0.index)\n",
    "    y_TESTset1 = pd.DataFrame(y_TESTset1,index=y_TESTset1.index)\n",
    "    y_TESTset2 = pd.DataFrame(y_TESTset2,index=y_TESTset2.index)\n",
    "    y_TESTset_df=pd.concat([y_TESTset0,y_TESTset1,y_TESTset2])\n",
    "    \n",
    "    y_pred_TEST_clust0_df= pd.DataFrame(y_pred_TEST_clust0,index=Clust0_TEST.index)\n",
    "    y_pred_TEST_clust1_df= pd.DataFrame(y_pred_TEST_clust1,index=Clust1_TEST.index)\n",
    "    y_pred_TEST_clust2_df= pd.DataFrame(y_pred_TEST_clust2,index=Clust2_TEST.index)\n",
    "    \n",
    "    y_pred_concat_TEST_df=pd.concat([y_pred_TEST_clust0_df,y_pred_TEST_clust1_df,y_pred_TEST_clust2_df])    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC  0.7937843406593406\n"
     ]
    }
   ],
   "source": [
    "#print(\"ROC_AUC \",roc_auc_score(y_TESTset0,y_pred_TEST_clust0, multi_class='ovr'))  \n",
    "\n",
    "\n",
    "#print(\"ROC_AUC \",roc_auc_score(y_TESTset1,y_pred_TEST_clust1, multi_class='ovr'))  \n",
    "\n",
    "\n",
    "print(\"ROC_AUC \",roc_auc_score(y_TESTset_df,y_pred_concat_TEST_df, multi_class='ovr'))  \n",
    "#ROC_AUC  0.8284254807692307\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
